{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-25T06:56:48.136587600Z",
     "start_time": "2024-04-25T06:56:48.135592300Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from lib.actor.LeeNet import LeeNetActor\n",
    "from lib.models.backbone.pure_RMT import PureRMT\n",
    "from lib.models.LeeNet.score_pureRMT_mlp import ScorePureRMTMLP\n",
    "from lib.models.head.mlp import MLP\n",
    "from lib.models.layer.patch_embed import PatchEmbed\n",
    "from lib.models.layer.score import PLScoreLayerUseConv\n",
    "from lib.trainer.LeeNet_trainer import LeeNetTrainer\n",
    "from lib.utils.base_funtion import build_dataloaders, get_optimizer_scheduler\n",
    "from lib.config.cfg_loader import env_setting\n",
    "from torch.nn.functional import l1_loss\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from lib.utils.box_ops import giou_loss\n",
    "from lib.utils.focal_loss import FocalLoss\n",
    "import torch\n",
    "\n",
    "\n",
    "def build_model(cfg):\n",
    "    backbone = PureRMT(cfg=cfg)\n",
    "    head = MLP(input_dim=10 * cfg.model.pureRMT.embed_dim[-1], hidden_dim=cfg.model.pureRMT.embed_dim[-1], output_dim=4, num_layers=2)\n",
    "    model = ScorePureRMTMLP(backbone, head, cfg)\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T07:09:41.270585700Z",
     "start_time": "2024-04-25T07:09:41.255623900Z"
    }
   },
   "id": "30fca21eced96d0a",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.6926]]],\n",
      "\n",
      "\n",
      "        [[[0.4538]]],\n",
      "\n",
      "\n",
      "        [[[0.4794]]],\n",
      "\n",
      "\n",
      "        [[[0.4758]]],\n",
      "\n",
      "\n",
      "        [[[0.4767]]],\n",
      "\n",
      "\n",
      "        [[[0.4753]]],\n",
      "\n",
      "\n",
      "        [[[0.6806]]],\n",
      "\n",
      "\n",
      "        [[[0.4682]]],\n",
      "\n",
      "\n",
      "        [[[0.5598]]],\n",
      "\n",
      "\n",
      "        [[[0.4778]]],\n",
      "\n",
      "\n",
      "        [[[0.4463]]],\n",
      "\n",
      "\n",
      "        [[[0.6138]]],\n",
      "\n",
      "\n",
      "        [[[0.4575]]],\n",
      "\n",
      "\n",
      "        [[[0.4763]]],\n",
      "\n",
      "\n",
      "        [[[0.4484]]],\n",
      "\n",
      "\n",
      "        [[[0.5834]]],\n",
      "\n",
      "\n",
      "        [[[0.4484]]],\n",
      "\n",
      "\n",
      "        [[[0.4950]]],\n",
      "\n",
      "\n",
      "        [[[0.5718]]],\n",
      "\n",
      "\n",
      "        [[[0.4920]]],\n",
      "\n",
      "\n",
      "        [[[0.5070]]],\n",
      "\n",
      "\n",
      "        [[[0.4809]]],\n",
      "\n",
      "\n",
      "        [[[0.4341]]],\n",
      "\n",
      "\n",
      "        [[[0.5413]]],\n",
      "\n",
      "\n",
      "        [[[0.6448]]],\n",
      "\n",
      "\n",
      "        [[[0.6006]]],\n",
      "\n",
      "\n",
      "        [[[0.5954]]],\n",
      "\n",
      "\n",
      "        [[[0.4436]]],\n",
      "\n",
      "\n",
      "        [[[0.4435]]],\n",
      "\n",
      "\n",
      "        [[[0.4591]]],\n",
      "\n",
      "\n",
      "        [[[0.4567]]],\n",
      "\n",
      "\n",
      "        [[[0.5736]]],\n",
      "\n",
      "\n",
      "        [[[0.4503]]],\n",
      "\n",
      "\n",
      "        [[[0.4563]]],\n",
      "\n",
      "\n",
      "        [[[0.5296]]],\n",
      "\n",
      "\n",
      "        [[[0.4736]]],\n",
      "\n",
      "\n",
      "        [[[0.5877]]],\n",
      "\n",
      "\n",
      "        [[[0.5028]]],\n",
      "\n",
      "\n",
      "        [[[0.4316]]],\n",
      "\n",
      "\n",
      "        [[[0.4952]]],\n",
      "\n",
      "\n",
      "        [[[0.4716]]],\n",
      "\n",
      "\n",
      "        [[[0.4670]]],\n",
      "\n",
      "\n",
      "        [[[0.4520]]],\n",
      "\n",
      "\n",
      "        [[[0.4752]]],\n",
      "\n",
      "\n",
      "        [[[0.6195]]],\n",
      "\n",
      "\n",
      "        [[[0.4694]]],\n",
      "\n",
      "\n",
      "        [[[0.5694]]],\n",
      "\n",
      "\n",
      "        [[[0.4603]]],\n",
      "\n",
      "\n",
      "        [[[0.4401]]],\n",
      "\n",
      "\n",
      "        [[[0.4737]]],\n",
      "\n",
      "\n",
      "        [[[0.4700]]],\n",
      "\n",
      "\n",
      "        [[[0.4539]]],\n",
      "\n",
      "\n",
      "        [[[0.4943]]],\n",
      "\n",
      "\n",
      "        [[[0.4957]]],\n",
      "\n",
      "\n",
      "        [[[0.6477]]],\n",
      "\n",
      "\n",
      "        [[[0.4655]]],\n",
      "\n",
      "\n",
      "        [[[0.4397]]],\n",
      "\n",
      "\n",
      "        [[[0.4706]]],\n",
      "\n",
      "\n",
      "        [[[0.7059]]],\n",
      "\n",
      "\n",
      "        [[[0.5661]]],\n",
      "\n",
      "\n",
      "        [[[0.5082]]],\n",
      "\n",
      "\n",
      "        [[[0.5216]]],\n",
      "\n",
      "\n",
      "        [[[0.4904]]],\n",
      "\n",
      "\n",
      "        [[[0.4585]]],\n",
      "\n",
      "\n",
      "        [[[0.5821]]],\n",
      "\n",
      "\n",
      "        [[[0.6337]]],\n",
      "\n",
      "\n",
      "        [[[0.4609]]],\n",
      "\n",
      "\n",
      "        [[[0.6323]]],\n",
      "\n",
      "\n",
      "        [[[0.4907]]],\n",
      "\n",
      "\n",
      "        [[[0.4907]]],\n",
      "\n",
      "\n",
      "        [[[0.4875]]],\n",
      "\n",
      "\n",
      "        [[[0.6817]]],\n",
      "\n",
      "\n",
      "        [[[0.4726]]],\n",
      "\n",
      "\n",
      "        [[[0.6001]]],\n",
      "\n",
      "\n",
      "        [[[0.5195]]],\n",
      "\n",
      "\n",
      "        [[[0.4522]]],\n",
      "\n",
      "\n",
      "        [[[0.5539]]],\n",
      "\n",
      "\n",
      "        [[[0.4974]]],\n",
      "\n",
      "\n",
      "        [[[0.5007]]],\n",
      "\n",
      "\n",
      "        [[[0.4860]]],\n",
      "\n",
      "\n",
      "        [[[0.5130]]],\n",
      "\n",
      "\n",
      "        [[[0.4682]]],\n",
      "\n",
      "\n",
      "        [[[0.5570]]],\n",
      "\n",
      "\n",
      "        [[[0.5508]]],\n",
      "\n",
      "\n",
      "        [[[0.4626]]],\n",
      "\n",
      "\n",
      "        [[[0.5441]]],\n",
      "\n",
      "\n",
      "        [[[0.4984]]],\n",
      "\n",
      "\n",
      "        [[[0.5137]]],\n",
      "\n",
      "\n",
      "        [[[0.5189]]],\n",
      "\n",
      "\n",
      "        [[[0.4309]]],\n",
      "\n",
      "\n",
      "        [[[0.4472]]],\n",
      "\n",
      "\n",
      "        [[[0.4570]]],\n",
      "\n",
      "\n",
      "        [[[0.4858]]],\n",
      "\n",
      "\n",
      "        [[[0.5653]]],\n",
      "\n",
      "\n",
      "        [[[0.5848]]],\n",
      "\n",
      "\n",
      "        [[[0.5238]]],\n",
      "\n",
      "\n",
      "        [[[0.4546]]],\n",
      "\n",
      "\n",
      "        [[[0.5095]]],\n",
      "\n",
      "\n",
      "        [[[0.4730]]],\n",
      "\n",
      "\n",
      "        [[[0.5551]]],\n",
      "\n",
      "\n",
      "        [[[0.4583]]],\n",
      "\n",
      "\n",
      "        [[[0.4533]]],\n",
      "\n",
      "\n",
      "        [[[0.5104]]],\n",
      "\n",
      "\n",
      "        [[[0.4590]]],\n",
      "\n",
      "\n",
      "        [[[0.6176]]],\n",
      "\n",
      "\n",
      "        [[[0.4965]]],\n",
      "\n",
      "\n",
      "        [[[0.5805]]],\n",
      "\n",
      "\n",
      "        [[[0.5151]]],\n",
      "\n",
      "\n",
      "        [[[0.5194]]],\n",
      "\n",
      "\n",
      "        [[[0.4918]]],\n",
      "\n",
      "\n",
      "        [[[0.4844]]],\n",
      "\n",
      "\n",
      "        [[[0.4309]]],\n",
      "\n",
      "\n",
      "        [[[0.5434]]],\n",
      "\n",
      "\n",
      "        [[[0.6162]]],\n",
      "\n",
      "\n",
      "        [[[0.4699]]],\n",
      "\n",
      "\n",
      "        [[[0.4764]]],\n",
      "\n",
      "\n",
      "        [[[0.7018]]],\n",
      "\n",
      "\n",
      "        [[[0.4603]]],\n",
      "\n",
      "\n",
      "        [[[0.6646]]],\n",
      "\n",
      "\n",
      "        [[[0.4890]]],\n",
      "\n",
      "\n",
      "        [[[0.6289]]],\n",
      "\n",
      "\n",
      "        [[[0.5507]]],\n",
      "\n",
      "\n",
      "        [[[0.5069]]],\n",
      "\n",
      "\n",
      "        [[[0.5678]]],\n",
      "\n",
      "\n",
      "        [[[0.4925]]],\n",
      "\n",
      "\n",
      "        [[[0.4848]]],\n",
      "\n",
      "\n",
      "        [[[0.5566]]],\n",
      "\n",
      "\n",
      "        [[[0.4495]]]], device='cuda:2', grad_fn=<SigmoidBackward>)\n",
      "value shape torch.Size([128, 1, 1, 1])\n",
      "rgb shape torch.Size([128, 96, 8, 8])\n",
      "modal shape torch.Size([128, 96, 8, 8])\n",
      "tensor([[[[0.4681]]],\n",
      "\n",
      "\n",
      "        [[[0.5047]]],\n",
      "\n",
      "\n",
      "        [[[0.4551]]],\n",
      "\n",
      "\n",
      "        [[[0.4879]]],\n",
      "\n",
      "\n",
      "        [[[0.5039]]],\n",
      "\n",
      "\n",
      "        [[[0.5307]]],\n",
      "\n",
      "\n",
      "        [[[0.6207]]],\n",
      "\n",
      "\n",
      "        [[[0.4521]]],\n",
      "\n",
      "\n",
      "        [[[0.6016]]],\n",
      "\n",
      "\n",
      "        [[[0.5133]]],\n",
      "\n",
      "\n",
      "        [[[0.4542]]],\n",
      "\n",
      "\n",
      "        [[[0.4681]]],\n",
      "\n",
      "\n",
      "        [[[0.4819]]],\n",
      "\n",
      "\n",
      "        [[[0.7772]]],\n",
      "\n",
      "\n",
      "        [[[0.5318]]],\n",
      "\n",
      "\n",
      "        [[[0.5310]]],\n",
      "\n",
      "\n",
      "        [[[0.5765]]],\n",
      "\n",
      "\n",
      "        [[[0.6353]]],\n",
      "\n",
      "\n",
      "        [[[0.4737]]],\n",
      "\n",
      "\n",
      "        [[[0.4681]]],\n",
      "\n",
      "\n",
      "        [[[0.7425]]],\n",
      "\n",
      "\n",
      "        [[[0.5346]]],\n",
      "\n",
      "\n",
      "        [[[0.5503]]],\n",
      "\n",
      "\n",
      "        [[[0.4653]]],\n",
      "\n",
      "\n",
      "        [[[0.4429]]],\n",
      "\n",
      "\n",
      "        [[[0.4779]]],\n",
      "\n",
      "\n",
      "        [[[0.4681]]],\n",
      "\n",
      "\n",
      "        [[[0.4734]]],\n",
      "\n",
      "\n",
      "        [[[0.4907]]],\n",
      "\n",
      "\n",
      "        [[[0.4681]]],\n",
      "\n",
      "\n",
      "        [[[0.5663]]],\n",
      "\n",
      "\n",
      "        [[[0.4741]]],\n",
      "\n",
      "\n",
      "        [[[0.4709]]],\n",
      "\n",
      "\n",
      "        [[[0.5331]]],\n",
      "\n",
      "\n",
      "        [[[0.5376]]],\n",
      "\n",
      "\n",
      "        [[[0.4681]]],\n",
      "\n",
      "\n",
      "        [[[0.6342]]],\n",
      "\n",
      "\n",
      "        [[[0.4952]]],\n",
      "\n",
      "\n",
      "        [[[0.4965]]],\n",
      "\n",
      "\n",
      "        [[[0.4684]]],\n",
      "\n",
      "\n",
      "        [[[0.5062]]],\n",
      "\n",
      "\n",
      "        [[[0.4555]]],\n",
      "\n",
      "\n",
      "        [[[0.4681]]],\n",
      "\n",
      "\n",
      "        [[[0.5662]]],\n",
      "\n",
      "\n",
      "        [[[0.4587]]],\n",
      "\n",
      "\n",
      "        [[[0.5706]]],\n",
      "\n",
      "\n",
      "        [[[0.7062]]],\n",
      "\n",
      "\n",
      "        [[[0.4681]]],\n",
      "\n",
      "\n",
      "        [[[0.4681]]],\n",
      "\n",
      "\n",
      "        [[[0.5223]]],\n",
      "\n",
      "\n",
      "        [[[0.5393]]],\n",
      "\n",
      "\n",
      "        [[[0.4773]]],\n",
      "\n",
      "\n",
      "        [[[0.5871]]],\n",
      "\n",
      "\n",
      "        [[[0.5109]]],\n",
      "\n",
      "\n",
      "        [[[0.4789]]],\n",
      "\n",
      "\n",
      "        [[[0.4908]]],\n",
      "\n",
      "\n",
      "        [[[0.4731]]],\n",
      "\n",
      "\n",
      "        [[[0.4681]]],\n",
      "\n",
      "\n",
      "        [[[0.4605]]],\n",
      "\n",
      "\n",
      "        [[[0.4818]]],\n",
      "\n",
      "\n",
      "        [[[0.4446]]],\n",
      "\n",
      "\n",
      "        [[[0.5615]]],\n",
      "\n",
      "\n",
      "        [[[0.4902]]],\n",
      "\n",
      "\n",
      "        [[[0.4655]]],\n",
      "\n",
      "\n",
      "        [[[0.5153]]],\n",
      "\n",
      "\n",
      "        [[[0.4681]]],\n",
      "\n",
      "\n",
      "        [[[0.4598]]],\n",
      "\n",
      "\n",
      "        [[[0.4476]]],\n",
      "\n",
      "\n",
      "        [[[0.5663]]],\n",
      "\n",
      "\n",
      "        [[[0.7509]]],\n",
      "\n",
      "\n",
      "        [[[0.4681]]],\n",
      "\n",
      "\n",
      "        [[[0.4308]]],\n",
      "\n",
      "\n",
      "        [[[0.4931]]],\n",
      "\n",
      "\n",
      "        [[[0.5483]]],\n",
      "\n",
      "\n",
      "        [[[0.4676]]],\n",
      "\n",
      "\n",
      "        [[[0.4620]]],\n",
      "\n",
      "\n",
      "        [[[0.6126]]],\n",
      "\n",
      "\n",
      "        [[[0.5600]]],\n",
      "\n",
      "\n",
      "        [[[0.7362]]],\n",
      "\n",
      "\n",
      "        [[[0.4714]]],\n",
      "\n",
      "\n",
      "        [[[0.4910]]],\n",
      "\n",
      "\n",
      "        [[[0.4640]]],\n",
      "\n",
      "\n",
      "        [[[0.4909]]],\n",
      "\n",
      "\n",
      "        [[[0.4615]]],\n",
      "\n",
      "\n",
      "        [[[0.4681]]],\n",
      "\n",
      "\n",
      "        [[[0.5769]]],\n",
      "\n",
      "\n",
      "        [[[0.4724]]],\n",
      "\n",
      "\n",
      "        [[[0.4741]]],\n",
      "\n",
      "\n",
      "        [[[0.4451]]],\n",
      "\n",
      "\n",
      "        [[[0.6190]]],\n",
      "\n",
      "\n",
      "        [[[0.4835]]],\n",
      "\n",
      "\n",
      "        [[[0.4939]]],\n",
      "\n",
      "\n",
      "        [[[0.5801]]],\n",
      "\n",
      "\n",
      "        [[[0.7708]]],\n",
      "\n",
      "\n",
      "        [[[0.4695]]],\n",
      "\n",
      "\n",
      "        [[[0.4420]]],\n",
      "\n",
      "\n",
      "        [[[0.4758]]],\n",
      "\n",
      "\n",
      "        [[[0.4681]]],\n",
      "\n",
      "\n",
      "        [[[0.4542]]],\n",
      "\n",
      "\n",
      "        [[[0.6679]]],\n",
      "\n",
      "\n",
      "        [[[0.4681]]],\n",
      "\n",
      "\n",
      "        [[[0.5382]]],\n",
      "\n",
      "\n",
      "        [[[0.4681]]],\n",
      "\n",
      "\n",
      "        [[[0.4605]]],\n",
      "\n",
      "\n",
      "        [[[0.4883]]],\n",
      "\n",
      "\n",
      "        [[[0.4985]]],\n",
      "\n",
      "\n",
      "        [[[0.4687]]],\n",
      "\n",
      "\n",
      "        [[[0.4681]]],\n",
      "\n",
      "\n",
      "        [[[0.5045]]],\n",
      "\n",
      "\n",
      "        [[[0.4681]]],\n",
      "\n",
      "\n",
      "        [[[0.4851]]],\n",
      "\n",
      "\n",
      "        [[[0.4681]]],\n",
      "\n",
      "\n",
      "        [[[0.4920]]],\n",
      "\n",
      "\n",
      "        [[[0.6139]]],\n",
      "\n",
      "\n",
      "        [[[0.4548]]],\n",
      "\n",
      "\n",
      "        [[[0.5721]]],\n",
      "\n",
      "\n",
      "        [[[0.6845]]],\n",
      "\n",
      "\n",
      "        [[[0.4626]]],\n",
      "\n",
      "\n",
      "        [[[0.4601]]],\n",
      "\n",
      "\n",
      "        [[[0.6039]]],\n",
      "\n",
      "\n",
      "        [[[0.4681]]],\n",
      "\n",
      "\n",
      "        [[[0.4339]]],\n",
      "\n",
      "\n",
      "        [[[0.6003]]],\n",
      "\n",
      "\n",
      "        [[[0.4800]]],\n",
      "\n",
      "\n",
      "        [[[0.4503]]],\n",
      "\n",
      "\n",
      "        [[[0.4812]]],\n",
      "\n",
      "\n",
      "        [[[0.5194]]],\n",
      "\n",
      "\n",
      "        [[[0.4681]]]], device='cuda:2', grad_fn=<SigmoidBackward>)\n",
      "value shape torch.Size([128, 1, 1, 1])\n",
      "rgb shape torch.Size([128, 96, 20, 20])\n",
      "modal shape torch.Size([128, 96, 20, 20])\n"
     ]
    }
   ],
   "source": [
    "cfg = env_setting(cfg_name=None)\n",
    "\n",
    "loader_train, loader_val = build_dataloaders(cfg)\n",
    "\n",
    "device = torch.device(\"cuda:2\")\n",
    "patch_embed = PatchEmbed(patch_size=16, in_chans=3, embed_dim=96, flatten=False).to(device)\n",
    "score = PLScoreLayerUseConv(embed_dim=96).to(device)\n",
    "\n",
    "for i,data in enumerate(loader_train):\n",
    "    \n",
    "    data = data.to(device)\n",
    "    \n",
    "    x = data['search_images'][0].view(-1, *data['search_images'].shape[2:])\n",
    "    z = data['template_images'][0].view(-1, *data['template_images'].shape[2:])\n",
    "\n",
    "    x_rgb = x[:, :3, :, :]\n",
    "    z_rgb = z[:, :3, :, :]\n",
    "\n",
    "    # get modal information (B,C,H,W)\n",
    "    x_modal = x[:, 3:, :, :]\n",
    "    z_modal = z[:, 3:, :, :]\n",
    "\n",
    "    # patch embedding      ->(B,C:Embed_dim,P_N,P_N) P_N = patch_nums(H / patch_size, W / patch_size)\n",
    "    x_rgb, _ = patch_embed(x_rgb)\n",
    "    z_rgb, _ = patch_embed(z_rgb)\n",
    "\n",
    "    x_modal, _ = patch_embed(x_modal)\n",
    "    z_modal, _ = patch_embed(z_modal)\n",
    "\n",
    "    # use score function\n",
    "    t = score(z_rgb,z_modal)  # (B,1,P_N,P_N) \n",
    "    s = score(x_rgb,x_modal)\n",
    "    break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-25T07:41:34.342422400Z",
     "start_time": "2024-04-25T07:40:53.865902200Z"
    }
   },
   "id": "4e91341746e0ae60",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# cfg = env_setting(cfg_name=None)\n",
    "# \n",
    "# loader_train, loader_val = build_dataloaders(cfg)\n",
    "# \n",
    "# net = build_model(cfg)\n",
    "# \n",
    "# focal_loss = FocalLoss()\n",
    "# objective = {'giou': giou_loss, 'l1': l1_loss, 'focal': focal_loss, 'cls': BCEWithLogitsLoss()}\n",
    "# loss_weight = {'giou': cfg.train.GIOU_weight, 'l1': cfg.train.L1_weight, 'focal': 1., 'cls': 1.0}\n",
    "# actor = LeeNetActor(net=net, objective=objective, loss_weight=loss_weight, cfg=cfg)\n",
    "# \n",
    "# optimizer, lr_scheduler = get_optimizer_scheduler(net, cfg)\n",
    "# \n",
    "# # location loss 没计算出来\n",
    "# \n",
    "# trainer = LeeNetTrainer(actor=actor, loaders=[loader_train, loader_val], optimizer=optimizer, lr_scheduler=lr_scheduler, cfg=cfg)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-04-25T06:56:12.774679700Z"
    }
   },
   "id": "99089b02971c220a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# trainer.train(cfg.train.epoch,load_latest=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T05:20:11.697385300Z",
     "start_time": "2024-04-21T05:20:11.681400400Z"
    }
   },
   "id": "1057de9bd0aeecbb",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0005\n"
     ]
    }
   ],
   "source": [
    "# trainer.load_checkpoint()\n",
    "# optimizer = trainer.optimizer\n",
    "# \n",
    "# optimizer.param_groups[0]['lr'] = 0.0005\n",
    "# \n",
    "# for params in optimizer.param_groups:\n",
    "#     print(params['lr'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T05:31:33.927120400Z",
     "start_time": "2024-04-21T05:31:33.444400500Z"
    }
   },
   "id": "65649e6829143bea",
   "execution_count": 11
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
