{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from lib.utils.base_funtion import build_dataloaders\n",
    "from lib.config.cfg_loader import  env_setting\n",
    "cfg = env_setting(cfg_name=None)\n",
    "loader_train, loader_val = build_dataloaders(cfg)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "99089b02971c220a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:90: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = batch[0].storage()._new_shared(numel)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [1572864], which does not match the required output shape [1, 16, 6, 128, 128]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [64], which does not match the required output shape [1, 16, 4]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [9830400], which does not match the required output shape [1, 16, 6, 320, 320]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:90: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = batch[0].storage()._new_shared(numel)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [1572864], which does not match the required output shape [1, 16, 6, 128, 128]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [64], which does not match the required output shape [1, 16, 4]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [9830400], which does not match the required output shape [1, 16, 6, 320, 320]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:90: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = batch[0].storage()._new_shared(numel)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [1572864], which does not match the required output shape [1, 16, 6, 128, 128]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [64], which does not match the required output shape [1, 16, 4]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [9830400], which does not match the required output shape [1, 16, 6, 320, 320]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:90: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = batch[0].storage()._new_shared(numel)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [1572864], which does not match the required output shape [1, 16, 6, 128, 128]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [64], which does not match the required output shape [1, 16, 4]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [9830400], which does not match the required output shape [1, 16, 6, 320, 320]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:90: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = batch[0].storage()._new_shared(numel)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [1572864], which does not match the required output shape [1, 16, 6, 128, 128]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [64], which does not match the required output shape [1, 16, 4]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [9830400], which does not match the required output shape [1, 16, 6, 320, 320]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:90: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = batch[0].storage()._new_shared(numel)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [1572864], which does not match the required output shape [1, 16, 6, 128, 128]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [64], which does not match the required output shape [1, 16, 4]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [9830400], which does not match the required output shape [1, 16, 6, 320, 320]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:90: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = batch[0].storage()._new_shared(numel)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [1572864], which does not match the required output shape [1, 16, 6, 128, 128]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [64], which does not match the required output shape [1, 16, 4]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [9830400], which does not match the required output shape [1, 16, 6, 320, 320]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:90: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  storage = batch[0].storage()._new_shared(numel)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [1572864], which does not match the required output shape [1, 16, 6, 128, 128]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [64], which does not match the required output shape [1, 16, 4]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [9830400], which does not match the required output shape [1, 16, 6, 320, 320]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "TensorDict([('template_images', tensor([[[[[ 1.7095e+00,  1.6741e+00,  1.6386e+00,  ...,  1.2311e+00,\n",
      "             1.2488e+00,  1.2133e+00],\n",
      "           [ 1.7272e+00,  1.7095e+00,  1.6918e+00,  ...,  1.1956e+00,\n",
      "             1.1956e+00,  1.1956e+00],\n",
      "           [ 1.7627e+00,  1.7449e+00,  1.7449e+00,  ...,  1.1779e+00,\n",
      "             1.1602e+00,  1.1779e+00],\n",
      "           ...,\n",
      "           [-6.6491e-01, -7.0035e-01, -6.8263e-01,  ..., -1.6572e+00,\n",
      "            -1.2497e+00, -7.1807e-01],\n",
      "           [-6.8263e-01, -6.8263e-01, -7.0035e-01,  ..., -1.3560e+00,\n",
      "            -1.4268e+00, -7.0035e-01],\n",
      "           [-6.8263e-01, -6.8263e-01, -7.0035e-01,  ..., -4.7000e-01,\n",
      "            -5.0544e-01, -5.0544e-01]],\n",
      "\n",
      "          [[ 1.8409e+00,  1.8047e+00,  1.8047e+00,  ...,  1.4967e+00,\n",
      "             1.5148e+00,  1.4786e+00],\n",
      "           [ 1.8590e+00,  1.8409e+00,  1.8590e+00,  ...,  1.4605e+00,\n",
      "             1.4605e+00,  1.4605e+00],\n",
      "           [ 1.8409e+00,  1.8228e+00,  1.8590e+00,  ...,  1.4424e+00,\n",
      "             1.4061e+00,  1.4242e+00],\n",
      "           ...,\n",
      "           [-7.9299e-02, -9.7414e-02, -7.9299e-02,  ..., -1.4923e+00,\n",
      "            -8.5824e-01, -1.1553e-01],\n",
      "           [-9.7414e-02, -7.9299e-02, -9.7414e-02,  ..., -1.1300e+00,\n",
      "            -9.8505e-01, -1.1553e-01],\n",
      "           [-9.7414e-02, -7.9299e-02, -9.7414e-02,  ..., -1.6987e-01,\n",
      "            -4.3069e-02,  4.7505e-02]],\n",
      "\n",
      "          [[ 2.1090e+00,  2.0730e+00,  2.0549e+00,  ...,  1.7123e+00,\n",
      "             1.7303e+00,  1.6942e+00],\n",
      "           [ 2.1271e+00,  2.1090e+00,  2.1090e+00,  ...,  1.6762e+00,\n",
      "             1.6762e+00,  1.6762e+00],\n",
      "           [ 2.1271e+00,  2.1090e+00,  2.1451e+00,  ...,  1.6582e+00,\n",
      "             1.6942e+00,  1.6942e+00],\n",
      "           ...,\n",
      "           [-1.6331e-01, -1.8134e-01, -1.6331e-01,  ..., -1.4618e+00,\n",
      "            -9.5683e-01, -2.3545e-01],\n",
      "           [-1.8134e-01, -1.6331e-01, -1.6331e-01,  ..., -1.0831e+00,\n",
      "            -1.0470e+00, -2.1741e-01],\n",
      "           [-1.6331e-01, -1.6331e-01, -1.4528e-01,  ..., -7.3138e-02,\n",
      "            -1.9035e-02,  1.7034e-02]],\n",
      "\n",
      "          [[-2.1179e+00, -2.1179e+00, -2.1179e+00,  ...,  1.5018e-01,\n",
      "             1.5018e-01,  1.5018e-01],\n",
      "           [-2.5736e-01,  1.5018e-01,  1.5018e-01,  ...,  1.5018e-01,\n",
      "             1.5018e-01,  1.5018e-01],\n",
      "           [-1.6395e+00, -1.6395e+00, -1.6395e+00,  ...,  1.5018e-01,\n",
      "             1.5018e-01,  1.5018e-01],\n",
      "           ...,\n",
      "           [-2.1179e+00, -2.1179e+00, -2.1179e+00,  ..., -2.1179e+00,\n",
      "            -9.4842e-01,  1.6209e+00],\n",
      "           [-2.1179e+00, -2.1179e+00, -2.1179e+00,  ..., -2.1179e+00,\n",
      "            -2.1179e+00, -1.6040e+00],\n",
      "           [-2.1179e+00, -2.1179e+00, -2.1179e+00,  ..., -2.1179e+00,\n",
      "            -2.1179e+00, -2.1179e+00]],\n",
      "\n",
      "          [[-2.0357e+00, -2.0357e+00, -2.0357e+00,  ..., -2.0357e+00,\n",
      "            -2.0357e+00, -2.0357e+00],\n",
      "           [-2.0357e+00, -2.0357e+00, -2.0357e+00,  ..., -2.0357e+00,\n",
      "            -2.0357e+00, -2.0357e+00],\n",
      "           [-2.0357e+00, -2.0357e+00, -2.0357e+00,  ..., -2.0357e+00,\n",
      "            -2.0357e+00, -2.0357e+00],\n",
      "           ...,\n",
      "           [-2.0357e+00, -2.0357e+00, -2.0357e+00,  ...,  1.3699e+00,\n",
      "             1.5148e+00, -1.0575e+00],\n",
      "           [-2.0357e+00, -2.0357e+00, -2.0357e+00,  ...,  1.3337e+00,\n",
      "             1.2612e+00,  1.6054e+00],\n",
      "           [-2.0357e+00, -2.0357e+00, -2.0357e+00,  ...,  1.2793e+00,\n",
      "             1.2250e+00,  1.2612e+00]],\n",
      "\n",
      "          [[ 5.0396e-01,  5.0396e-01,  5.0396e-01,  ..., -1.8044e+00,\n",
      "            -1.8044e+00, -1.8044e+00],\n",
      "           [-1.3897e+00, -1.8044e+00, -1.8044e+00,  ..., -1.8044e+00,\n",
      "            -1.8044e+00, -1.8044e+00],\n",
      "           [ 3.5069e-02,  3.5069e-02,  3.5069e-02,  ..., -1.8044e+00,\n",
      "            -1.8044e+00, -1.8044e+00],\n",
      "           ...,\n",
      "           [ 5.0396e-01,  5.0396e-01,  5.0396e-01,  ...,  2.6400e+00,\n",
      "             1.6041e+00, -1.8044e+00],\n",
      "           [ 5.0396e-01,  5.0396e-01,  5.0396e-01,  ...,  2.6400e+00,\n",
      "             2.6400e+00,  2.2713e+00],\n",
      "           [ 5.0396e-01,  5.0396e-01,  5.0396e-01,  ...,  2.6400e+00,\n",
      "             2.6400e+00,  2.6400e+00]]],\n",
      "\n",
      "\n",
      "         [[[ 3.0972e-01,  3.7868e-01,  2.9592e-01,  ..., -2.6960e-01,\n",
      "            -3.1098e-01, -4.3512e-01],\n",
      "           [ 3.6489e-01,  3.5110e-01,  3.0972e-01,  ..., -3.1098e-01,\n",
      "            -3.3857e-01, -4.2133e-01],\n",
      "           [ 3.2351e-01,  3.5110e-01,  2.4075e-01,  ..., -2.1443e-01,\n",
      "            -3.5236e-01, -4.2133e-01],\n",
      "           ...,\n",
      "           [-8.2133e-01, -8.0754e-01, -7.7995e-01,  ..., -1.9110e+00,\n",
      "            -1.5800e+00, -1.6627e+00],\n",
      "           [-8.4892e-01, -8.0754e-01, -8.0754e-01,  ..., -2.0903e+00,\n",
      "            -2.0351e+00, -2.0489e+00],\n",
      "           [-8.3513e-01, -8.2133e-01, -8.2133e-01,  ..., -2.1179e+00,\n",
      "            -1.9524e+00, -1.9662e+00]],\n",
      "\n",
      "          [[ 1.9227e-01,  2.2048e-01,  1.3587e-01,  ..., -1.1795e-01,\n",
      "            -7.5650e-02, -4.7447e-02],\n",
      "           [ 2.3458e-01,  2.0637e-01,  1.6407e-01,  ..., -1.7436e-01,\n",
      "            -1.0385e-01, -4.7447e-02],\n",
      "           [ 2.0637e-01,  2.0637e-01,  9.3565e-02,  ..., -8.9751e-02,\n",
      "            -1.3205e-01, -3.3346e-02],\n",
      "           ...,\n",
      "           [-1.3166e+00, -1.3307e+00, -1.3025e+00,  ..., -1.2178e+00,\n",
      "            -7.5251e-01, -8.6532e-01],\n",
      "           [-1.3448e+00, -1.3307e+00, -1.3307e+00,  ..., -1.5140e+00,\n",
      "            -1.4435e+00, -1.4576e+00],\n",
      "           [-1.3448e+00, -1.3448e+00, -1.3448e+00,  ..., -1.6409e+00,\n",
      "            -1.4858e+00, -1.4717e+00]],\n",
      "\n",
      "          [[ 1.0479e-01,  1.4691e-01,  9.0755e-02,  ...,  6.2678e-02,\n",
      "             1.7499e-01,  2.4518e-01],\n",
      "           [ 1.3287e-01,  1.0479e-01,  6.2678e-02,  ...,  2.0562e-02,\n",
      "             1.4691e-01,  2.7326e-01],\n",
      "           [ 9.0755e-02,  9.0755e-02, -2.1553e-02,  ...,  1.0479e-01,\n",
      "             1.3287e-01,  2.7326e-01],\n",
      "           ...,\n",
      "           [-1.3693e+00, -1.3973e+00, -1.3973e+00,  ..., -6.3925e-01,\n",
      "            -1.7598e-01, -2.3213e-01],\n",
      "           [-1.3973e+00, -1.3973e+00, -1.4114e+00,  ..., -8.6386e-01,\n",
      "            -8.0771e-01, -8.2175e-01],\n",
      "           [-1.3833e+00, -1.4114e+00, -1.4394e+00,  ..., -9.9021e-01,\n",
      "            -8.4983e-01, -8.3579e-01]],\n",
      "\n",
      "          [[ 6.1437e-02,  6.1437e-02,  6.1437e-02,  ...,  1.3994e+00,\n",
      "             1.3994e+00,  1.3994e+00],\n",
      "           [ 3.3850e-02,  4.7644e-02,  6.1437e-02,  ...,  1.3994e+00,\n",
      "             1.3994e+00,  1.3994e+00],\n",
      "           [ 6.2640e-03,  6.2640e-03,  6.1437e-02,  ...,  1.3994e+00,\n",
      "             1.3994e+00,  1.3994e+00],\n",
      "           ...,\n",
      "           [-4.8909e-02,  1.1925e+00,  1.2752e+00,  ...,  1.3994e+00,\n",
      "             1.3994e+00,  1.3994e+00],\n",
      "           [-3.5236e-01,  1.9937e-01, -2.9719e-01,  ...,  1.3994e+00,\n",
      "             1.3994e+00,  1.3994e+00],\n",
      "           [-3.5236e-01, -3.5236e-01, -3.5236e-01,  ...,  1.3994e+00,\n",
      "             1.3994e+00,  1.3994e+00]],\n",
      "\n",
      "          [[ 1.5601e+00,  1.5601e+00,  1.5601e+00,  ...,  7.8452e-01,\n",
      "             8.1272e-01,  8.4093e-01],\n",
      "           [ 1.5601e+00,  1.5601e+00,  1.5601e+00,  ...,  7.8452e-01,\n",
      "             8.2683e-01,  8.4093e-01],\n",
      "           [ 1.5601e+00,  1.5601e+00,  1.5601e+00,  ...,  8.4093e-01,\n",
      "             8.4093e-01,  8.8323e-01],\n",
      "           ...,\n",
      "           [-1.5986e+00,  9.1143e-01,  4.0379e-01,  ...,  7.8452e-01,\n",
      "             7.8452e-01,  7.8452e-01],\n",
      "           [-2.0357e+00, -1.6973e+00, -1.9934e+00,  ...,  7.8452e-01,\n",
      "             7.8452e-01,  7.8452e-01],\n",
      "           [-2.0357e+00, -2.0357e+00, -2.0357e+00,  ...,  7.8452e-01,\n",
      "             7.8452e-01,  7.8452e-01]],\n",
      "\n",
      "          [[-4.2867e-01, -4.2867e-01, -4.2867e-01,  ..., -1.8044e+00,\n",
      "            -1.8044e+00, -1.8044e+00],\n",
      "           [-4.0059e-01, -4.1463e-01, -4.2867e-01,  ..., -1.8044e+00,\n",
      "            -1.8044e+00, -1.8044e+00],\n",
      "           [-3.7252e-01, -3.7252e-01, -4.2867e-01,  ..., -1.8044e+00,\n",
      "            -1.8044e+00, -1.8044e+00],\n",
      "           ...,\n",
      "           [-1.8044e+00, -1.6360e+00, -1.7904e+00,  ..., -1.8044e+00,\n",
      "            -1.8044e+00, -1.8044e+00],\n",
      "           [-1.8044e+00, -1.8044e+00, -1.8044e+00,  ..., -1.8044e+00,\n",
      "            -1.8044e+00, -1.8044e+00],\n",
      "           [-1.8044e+00, -1.8044e+00, -1.8044e+00,  ..., -1.8044e+00,\n",
      "            -1.8044e+00, -1.8044e+00]]],\n",
      "\n",
      "\n",
      "         [[[ 2.1021e-01,  2.1021e-01,  2.6520e-01,  ...,  1.6401e+00,\n",
      "             1.8601e+00,  1.8967e+00],\n",
      "           [ 2.1021e-01,  2.1021e-01,  2.6520e-01,  ...,  1.6217e+00,\n",
      "             1.8601e+00,  1.8967e+00],\n",
      "           [ 1.7355e-01,  1.9188e-01,  2.2854e-01,  ...,  1.6217e+00,\n",
      "             1.8601e+00,  1.8967e+00],\n",
      "           ...,\n",
      "           [ 4.3019e-01,  4.3019e-01,  4.3019e-01,  ...,  5.7684e-01,\n",
      "             5.7684e-01,  5.7684e-01],\n",
      "           [ 4.4852e-01,  4.4852e-01,  4.4852e-01,  ...,  5.7684e-01,\n",
      "             5.7684e-01,  5.7684e-01],\n",
      "           [ 4.4852e-01,  4.4852e-01,  4.4852e-01,  ...,  5.7684e-01,\n",
      "             5.7684e-01,  5.7684e-01]],\n",
      "\n",
      "          [[-3.1156e-01, -3.1156e-01, -3.1156e-01,  ...,  8.5037e-01,\n",
      "             1.0753e+00,  1.0940e+00],\n",
      "           [-3.1156e-01, -3.1156e-01, -3.1156e-01,  ...,  8.5037e-01,\n",
      "             1.0753e+00,  1.0940e+00],\n",
      "           [-2.9282e-01, -2.9282e-01, -2.9282e-01,  ...,  8.5037e-01,\n",
      "             1.0378e+00,  1.0565e+00],\n",
      "           ...,\n",
      "           [ 7.0316e-03,  7.0316e-03,  7.0316e-03,  ...,  4.4513e-02,\n",
      "             6.3254e-02,  6.3254e-02],\n",
      "           [ 2.5772e-02,  2.5772e-02,  7.0316e-03,  ...,  4.4513e-02,\n",
      "             6.3254e-02,  6.3254e-02],\n",
      "           [ 2.5772e-02,  2.5772e-02,  7.0316e-03,  ...,  4.4513e-02,\n",
      "             6.3254e-02,  6.3254e-02]],\n",
      "\n",
      "          [[-4.6110e-01, -4.6110e-01, -4.2379e-01,  ...,  4.1580e-01,\n",
      "             5.2774e-01,  5.4640e-01],\n",
      "           [-4.6110e-01, -4.6110e-01, -4.4245e-01,  ...,  4.3445e-01,\n",
      "             5.4640e-01,  5.6506e-01],\n",
      "           [-4.6110e-01, -4.6110e-01, -4.6110e-01,  ...,  5.2774e-01,\n",
      "             6.5835e-01,  6.7700e-01],\n",
      "           ...,\n",
      "           [-2.5587e-01, -2.5587e-01, -2.5587e-01,  ..., -1.4393e-01,\n",
      "            -1.4393e-01, -1.4393e-01],\n",
      "           [-2.5587e-01, -2.5587e-01, -2.5587e-01,  ..., -1.6258e-01,\n",
      "            -1.6258e-01, -1.6258e-01],\n",
      "           [-2.5587e-01, -2.5587e-01, -2.5587e-01,  ..., -1.6258e-01,\n",
      "            -1.6258e-01, -1.6258e-01]],\n",
      "\n",
      "          [[ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "             2.2489e+00,  2.2489e+00],\n",
      "           [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "             2.2489e+00,  2.2489e+00],\n",
      "           [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "             2.2489e+00,  2.2489e+00],\n",
      "           ...,\n",
      "           [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "             2.2489e+00,  2.2489e+00],\n",
      "           [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "             2.2489e+00,  2.2489e+00],\n",
      "           [ 2.2489e+00,  2.2489e+00,  2.2489e+00,  ...,  2.2489e+00,\n",
      "             2.2489e+00,  2.2489e+00]],\n",
      "\n",
      "          [[ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "             2.4286e+00,  2.4286e+00],\n",
      "           [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "             2.4286e+00,  2.4286e+00],\n",
      "           [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "             2.4286e+00,  2.4286e+00],\n",
      "           ...,\n",
      "           [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "             2.4286e+00,  2.4286e+00],\n",
      "           [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "             2.4286e+00,  2.4286e+00],\n",
      "           [ 2.4286e+00,  2.4286e+00,  2.4286e+00,  ...,  2.4286e+00,\n",
      "             2.4286e+00,  2.4286e+00]],\n",
      "\n",
      "          [[ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "             2.6400e+00,  2.6400e+00],\n",
      "           [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "             2.6400e+00,  2.6400e+00],\n",
      "           [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "             2.6400e+00,  2.6400e+00],\n",
      "           ...,\n",
      "           [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "             2.6400e+00,  2.6400e+00],\n",
      "           [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "             2.6400e+00,  2.6400e+00],\n",
      "           [ 2.6400e+00,  2.6400e+00,  2.6400e+00,  ...,  2.6400e+00,\n",
      "             2.6400e+00,  2.6400e+00]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-6.7753e-01, -6.6204e-01, -6.6204e-01,  ...,  2.9821e-01,\n",
      "             3.1370e-01,  3.2919e-01],\n",
      "           [-6.4655e-01, -6.4655e-01, -6.4655e-01,  ...,  2.9821e-01,\n",
      "             3.1370e-01,  3.2919e-01],\n",
      "           [-6.1557e-01, -6.1557e-01, -6.1557e-01,  ...,  2.9821e-01,\n",
      "             3.1370e-01,  3.2919e-01],\n",
      "           ...,\n",
      "           [ 5.1505e-01,  5.3053e-01,  5.3053e-01,  ..., -8.7887e-01,\n",
      "            -1.0337e+00, -1.2041e+00],\n",
      "           [ 4.2212e-01,  4.2212e-01,  4.2212e-01,  ..., -7.8594e-01,\n",
      "            -9.2533e-01, -1.1577e+00],\n",
      "           [ 3.4468e-01,  3.2919e-01,  3.1370e-01,  ..., -7.7045e-01,\n",
      "            -8.7887e-01, -1.0802e+00]],\n",
      "\n",
      "          [[-5.9485e-01, -5.9485e-01, -5.7902e-01,  ...,  5.2934e-01,\n",
      "             5.4517e-01,  5.6100e-01],\n",
      "           [-5.7902e-01, -5.6318e-01, -5.6318e-01,  ...,  5.2934e-01,\n",
      "             5.4517e-01,  5.6100e-01],\n",
      "           [-5.3152e-01, -5.3152e-01, -5.3152e-01,  ...,  5.2934e-01,\n",
      "             5.2934e-01,  5.6100e-01],\n",
      "           ...,\n",
      "           [-1.6734e-01, -1.5151e-01, -1.5151e-01,  ..., -4.9985e-01,\n",
      "            -6.5819e-01, -8.4819e-01],\n",
      "           [-2.7818e-01, -2.7818e-01, -2.7818e-01,  ..., -3.4151e-01,\n",
      "            -4.9985e-01, -7.2152e-01],\n",
      "           [-3.8901e-01, -3.8901e-01, -3.8901e-01,  ..., -2.9401e-01,\n",
      "            -4.0485e-01, -6.1069e-01]],\n",
      "\n",
      "          [[-3.5422e-01, -3.5422e-01, -3.3846e-01,  ...,  5.9157e-01,\n",
      "             6.0734e-01,  6.2310e-01],\n",
      "           [-3.2270e-01, -3.2270e-01, -3.2270e-01,  ...,  5.9157e-01,\n",
      "             6.0734e-01,  6.2310e-01],\n",
      "           [-2.9117e-01, -2.9117e-01, -2.9117e-01,  ...,  6.0734e-01,\n",
      "             6.0734e-01,  6.3886e-01],\n",
      "           ...,\n",
      "           [-2.7541e-01, -2.5964e-01, -2.5964e-01,  ..., -6.8525e-01,\n",
      "            -8.4288e-01, -1.0163e+00],\n",
      "           [-3.8575e-01, -3.6999e-01, -3.5422e-01,  ..., -5.5915e-01,\n",
      "            -7.0101e-01, -9.2170e-01],\n",
      "           [-4.8033e-01, -4.6457e-01, -4.4880e-01,  ..., -5.2762e-01,\n",
      "            -6.3796e-01, -8.2712e-01]],\n",
      "\n",
      "          [[-2.1179e+00, -2.1179e+00, -2.1179e+00,  ..., -2.1179e+00,\n",
      "            -2.1179e+00, -2.1179e+00],\n",
      "           [-2.1179e+00, -2.1179e+00, -2.1179e+00,  ..., -2.1179e+00,\n",
      "            -2.1179e+00, -2.1179e+00],\n",
      "           [-2.1179e+00, -2.1179e+00, -2.1179e+00,  ..., -2.1179e+00,\n",
      "            -2.1179e+00, -2.1179e+00],\n",
      "           ...,\n",
      "           [ 1.8315e+00,  1.8315e+00,  1.8315e+00,  ..., -2.1179e+00,\n",
      "            -2.1179e+00, -2.1179e+00],\n",
      "           [ 1.8315e+00,  1.8315e+00,  1.8315e+00,  ..., -2.1179e+00,\n",
      "            -2.1179e+00, -2.1179e+00],\n",
      "           [ 1.8315e+00,  1.8315e+00,  1.8315e+00,  ..., -2.1179e+00,\n",
      "            -2.1179e+00, -2.1179e+00]],\n",
      "\n",
      "          [[-2.0357e+00, -2.0357e+00, -2.0357e+00,  ..., -2.0357e+00,\n",
      "            -2.0357e+00, -2.0357e+00],\n",
      "           [-2.0357e+00, -2.0357e+00, -2.0357e+00,  ..., -2.0357e+00,\n",
      "            -2.0357e+00, -2.0357e+00],\n",
      "           [-2.0357e+00, -2.0357e+00, -2.0357e+00,  ..., -2.0357e+00,\n",
      "            -2.0357e+00, -2.0357e+00],\n",
      "           ...,\n",
      "           [ 1.9544e+00,  1.9544e+00,  1.9544e+00,  ..., -2.0357e+00,\n",
      "            -2.0357e+00, -2.0357e+00],\n",
      "           [ 1.9544e+00,  1.9544e+00,  1.9544e+00,  ..., -2.0357e+00,\n",
      "            -2.0357e+00, -2.0357e+00],\n",
      "           [ 1.9544e+00,  1.9544e+00,  1.9544e+00,  ..., -2.0357e+00,\n",
      "            -2.0357e+00, -2.0357e+00]],\n",
      "\n",
      "          [[ 2.1326e-01,  2.1326e-01,  2.1326e-01,  ...,  1.2221e+00,\n",
      "             1.2221e+00,  1.2221e+00],\n",
      "           [ 2.1326e-01,  2.1326e-01,  2.1326e-01,  ...,  1.2221e+00,\n",
      "             1.2536e+00,  1.3009e+00],\n",
      "           [ 2.1326e-01,  2.1326e-01,  2.1326e-01,  ...,  1.2536e+00,\n",
      "             1.3009e+00,  1.3482e+00],\n",
      "           ...,\n",
      "           [-1.8044e+00, -1.8044e+00, -1.8044e+00,  ...,  2.1326e-01,\n",
      "             2.1326e-01,  2.1326e-01],\n",
      "           [-1.8044e+00, -1.8044e+00, -1.8044e+00,  ...,  2.1326e-01,\n",
      "             2.1326e-01,  2.1326e-01],\n",
      "           [-1.8044e+00, -1.8044e+00, -1.8044e+00,  ...,  2.1326e-01,\n",
      "             2.1326e-01,  2.1326e-01]]],\n",
      "\n",
      "\n",
      "         [[[-1.9845e+00, -1.9993e+00, -2.0141e+00,  ..., -2.5004e-01,\n",
      "             5.8012e-01,  1.1434e+00],\n",
      "           [-1.9845e+00, -2.0141e+00, -2.0290e+00,  ...,  8.0249e-01,\n",
      "             1.1731e+00,  1.4251e+00],\n",
      "           [-1.9993e+00, -2.0290e+00, -2.0438e+00,  ...,  1.6623e+00,\n",
      "             1.6623e+00,  1.6623e+00],\n",
      "           ...,\n",
      "           [-7.2442e-01, -8.5784e-01, -9.7643e-01,  ..., -2.0734e+00,\n",
      "            -2.0734e+00, -2.0586e+00],\n",
      "           [-8.5784e-01, -9.7643e-01, -1.0950e+00,  ..., -2.0883e+00,\n",
      "            -2.0883e+00, -2.0586e+00],\n",
      "           [-9.3196e-01, -1.0654e+00, -1.1988e+00,  ..., -2.0883e+00,\n",
      "            -2.0734e+00, -2.0586e+00]],\n",
      "\n",
      "          [[-1.7932e+00, -1.7932e+00, -1.8084e+00,  ...,  1.6179e-01,\n",
      "             6.3161e-01,  1.7834e+00],\n",
      "           [-1.7932e+00, -1.7781e+00, -1.7629e+00,  ...,  1.5258e+00,\n",
      "             1.7834e+00,  1.8289e+00],\n",
      "           [-1.8084e+00, -1.8235e+00, -1.8539e+00,  ...,  1.8289e+00,\n",
      "             1.8289e+00,  1.8289e+00],\n",
      "           ...,\n",
      "           [-8.0814e-01, -9.4454e-01, -1.0658e+00,  ..., -1.8842e+00,\n",
      "            -1.8842e+00, -1.9145e+00],\n",
      "           [-8.9907e-01, -1.0506e+00, -1.1264e+00,  ..., -1.8842e+00,\n",
      "            -1.8842e+00, -1.8235e+00],\n",
      "           [-9.5969e-01, -1.1112e+00, -1.2173e+00,  ..., -1.9145e+00,\n",
      "            -1.9599e+00, -1.8539e+00]],\n",
      "\n",
      "          [[-1.6988e+00, -1.7139e+00, -1.7441e+00,  ...,  4.2856e-01,\n",
      "             5.3418e-01,  6.3979e-01],\n",
      "           [-1.6988e+00, -1.7139e+00, -1.7441e+00,  ...,  2.0430e+00,\n",
      "             2.0430e+00,  2.0430e+00],\n",
      "           [-1.7290e+00, -1.7441e+00, -1.7743e+00,  ...,  2.0430e+00,\n",
      "             2.0430e+00,  2.0430e+00],\n",
      "           ...,\n",
      "           [-1.1255e+00, -1.2160e+00, -1.2764e+00,  ..., -1.7743e+00,\n",
      "            -1.7894e+00, -1.8044e+00],\n",
      "           [-1.1858e+00, -1.2764e+00, -1.3367e+00,  ..., -1.7743e+00,\n",
      "            -1.7743e+00, -1.7743e+00],\n",
      "           [-1.2462e+00, -1.3367e+00, -1.4122e+00,  ..., -1.7592e+00,\n",
      "            -1.7441e+00, -1.7290e+00]],\n",
      "\n",
      "          [[ 1.6623e+00,  1.6623e+00,  1.6623e+00,  ...,  1.6623e+00,\n",
      "             1.6623e+00,  1.6623e+00],\n",
      "           [ 1.6623e+00,  1.6623e+00,  1.6623e+00,  ...,  1.6623e+00,\n",
      "             1.6623e+00,  1.6623e+00],\n",
      "           [ 1.6623e+00,  1.6623e+00,  1.6623e+00,  ...,  1.6623e+00,\n",
      "             1.6623e+00,  1.6623e+00],\n",
      "           ...,\n",
      "           [ 8.4696e-01,  8.4696e-01,  8.4696e-01,  ...,  1.6623e+00,\n",
      "             1.6623e+00,  1.6623e+00],\n",
      "           [ 8.4696e-01,  8.4696e-01,  8.4696e-01,  ...,  1.6623e+00,\n",
      "             1.6623e+00,  1.6623e+00],\n",
      "           [ 8.4696e-01,  8.4696e-01,  8.4696e-01,  ...,  1.6623e+00,\n",
      "             1.6623e+00,  1.6623e+00]],\n",
      "\n",
      "          [[ 1.8289e+00,  1.8289e+00,  1.8289e+00,  ...,  1.8289e+00,\n",
      "             1.8289e+00,  1.8289e+00],\n",
      "           [ 1.8289e+00,  1.8289e+00,  1.8289e+00,  ...,  1.8289e+00,\n",
      "             1.8289e+00,  1.8289e+00],\n",
      "           [ 1.8289e+00,  1.8289e+00,  1.8289e+00,  ...,  1.8289e+00,\n",
      "             1.8289e+00,  1.8289e+00],\n",
      "           ...,\n",
      "           [-1.5811e+00, -1.5811e+00, -1.5811e+00,  ...,  1.8289e+00,\n",
      "             1.8289e+00,  1.8289e+00],\n",
      "           [-1.5811e+00, -1.5811e+00, -1.5811e+00,  ...,  1.8289e+00,\n",
      "             1.8289e+00,  1.8289e+00],\n",
      "           [-1.5811e+00, -1.5811e+00, -1.5811e+00,  ...,  1.8289e+00,\n",
      "             1.8289e+00,  1.8289e+00]],\n",
      "\n",
      "          [[ 2.0430e+00,  2.0430e+00,  2.0430e+00,  ...,  2.0430e+00,\n",
      "             2.0430e+00,  2.0430e+00],\n",
      "           [ 2.0430e+00,  2.0430e+00,  2.0430e+00,  ...,  2.0430e+00,\n",
      "             2.0430e+00,  2.0430e+00],\n",
      "           [ 2.0430e+00,  2.0430e+00,  2.0430e+00,  ...,  2.0430e+00,\n",
      "             2.0430e+00,  2.0430e+00],\n",
      "           ...,\n",
      "           [-1.3518e+00, -1.3518e+00, -1.3518e+00,  ...,  2.0430e+00,\n",
      "             2.0430e+00,  2.0430e+00],\n",
      "           [-1.3518e+00, -1.3518e+00, -1.3518e+00,  ...,  2.0430e+00,\n",
      "             2.0430e+00,  2.0430e+00],\n",
      "           [-1.3518e+00, -1.3518e+00, -1.3518e+00,  ...,  2.0430e+00,\n",
      "             2.0430e+00,  2.0430e+00]]],\n",
      "\n",
      "\n",
      "         [[[-1.2596e+00, -9.6370e-01, -5.6416e-01,  ..., -6.3815e-01,\n",
      "            -9.9329e-01, -1.2596e+00],\n",
      "           [-1.1709e+00, -8.8971e-01, -5.1977e-01,  ..., -6.6775e-01,\n",
      "            -1.0229e+00, -1.2744e+00],\n",
      "           [-1.0525e+00, -8.0092e-01, -4.7538e-01,  ..., -6.0856e-01,\n",
      "            -9.9329e-01, -1.2744e+00],\n",
      "           ...,\n",
      "           [ 6.4923e-01,  9.0079e-01,  1.2263e+00,  ...,  2.7930e-01,\n",
      "             2.7930e-01,  2.7930e-01],\n",
      "           [ 5.3085e-01,  7.3802e-01,  1.0044e+00,  ...,  2.7930e-01,\n",
      "             2.6450e-01,  2.6450e-01],\n",
      "           [ 5.0126e-01,  6.3444e-01,  8.2681e-01,  ...,  2.9409e-01,\n",
      "             2.7930e-01,  2.6450e-01]],\n",
      "\n",
      "          [[-1.4306e+00, -1.2188e+00, -8.8600e-01,  ..., -1.0827e+00,\n",
      "            -1.2642e+00, -1.4003e+00],\n",
      "           [-1.3852e+00, -1.1886e+00, -8.8600e-01,  ..., -1.0524e+00,\n",
      "            -1.2339e+00, -1.3550e+00],\n",
      "           [-1.3247e+00, -1.1432e+00, -8.7087e-01,  ..., -1.0070e+00,\n",
      "            -1.1886e+00, -1.2945e+00],\n",
      "           ...,\n",
      "           [ 1.1244e-01,  8.2183e-02,  6.7055e-02,  ..., -1.5986e-01,\n",
      "            -1.7499e-01, -1.9012e-01],\n",
      "           [ 2.1671e-02,  2.1671e-02,  3.6799e-02,  ..., -9.9351e-02,\n",
      "            -9.9351e-02, -8.4223e-02],\n",
      "           [-3.8840e-02, -2.3712e-02,  6.5436e-03,  ..., -3.8840e-02,\n",
      "            -5.3968e-02, -2.3712e-02]],\n",
      "\n",
      "          [[-1.3526e+00, -1.2773e+00, -1.0815e+00,  ..., -1.1719e+00,\n",
      "            -1.2321e+00, -1.2321e+00],\n",
      "           [-1.3225e+00, -1.2321e+00, -1.0514e+00,  ..., -1.1418e+00,\n",
      "            -1.2020e+00, -1.2171e+00],\n",
      "           [-1.2773e+00, -1.1719e+00, -9.9117e-01,  ..., -1.1117e+00,\n",
      "            -1.1719e+00, -1.2020e+00],\n",
      "           ...,\n",
      "           [-3.1344e-01, -3.1344e-01, -3.1344e-01,  ..., -4.3393e-01,\n",
      "            -4.3393e-01, -4.3393e-01],\n",
      "           [-3.5863e-01, -3.5863e-01, -3.5863e-01,  ..., -3.8875e-01,\n",
      "            -4.0381e-01, -4.1887e-01],\n",
      "           [-3.8875e-01, -3.8875e-01, -3.8875e-01,  ..., -3.4357e-01,\n",
      "            -3.7369e-01, -4.0381e-01]],\n",
      "\n",
      "          [[ 1.6555e+00,  1.6555e+00,  1.6555e+00,  ...,  1.6555e+00,\n",
      "             1.6555e+00,  1.6555e+00],\n",
      "           [ 1.6555e+00,  1.6555e+00,  1.6555e+00,  ...,  1.6555e+00,\n",
      "             1.6555e+00,  1.6555e+00],\n",
      "           [ 1.6555e+00,  1.6555e+00,  1.6555e+00,  ...,  1.6555e+00,\n",
      "             1.6555e+00,  1.6555e+00],\n",
      "           ...,\n",
      "           [-1.1413e+00,  2.4970e-01,  1.6555e+00,  ...,  1.6555e+00,\n",
      "             1.6555e+00,  1.6555e+00],\n",
      "           [-1.8566e-03,  8.2681e-01,  1.6555e+00,  ...,  1.6555e+00,\n",
      "             1.6555e+00,  1.6555e+00],\n",
      "           [ 1.6555e+00,  1.6555e+00,  1.6555e+00,  ...,  1.6555e+00,\n",
      "             1.6555e+00,  1.6555e+00]],\n",
      "\n",
      "          [[ 1.8219e+00,  1.8219e+00,  1.8219e+00,  ...,  1.8219e+00,\n",
      "             1.8219e+00,  1.8219e+00],\n",
      "           [ 1.8219e+00,  1.8219e+00,  1.8219e+00,  ...,  1.8219e+00,\n",
      "             1.8219e+00,  1.8219e+00],\n",
      "           [ 1.8219e+00,  1.8219e+00,  1.8219e+00,  ...,  1.8219e+00,\n",
      "             1.8219e+00,  1.8219e+00],\n",
      "           ...,\n",
      "           [-1.0373e+00,  3.8474e-01,  1.8219e+00,  ...,  1.8219e+00,\n",
      "             1.8219e+00,  1.8219e+00],\n",
      "           [ 1.2757e-01,  9.7473e-01,  1.8219e+00,  ...,  1.8219e+00,\n",
      "             1.8219e+00,  1.8219e+00],\n",
      "           [ 1.8219e+00,  1.8219e+00,  1.8219e+00,  ...,  1.8219e+00,\n",
      "             1.8219e+00,  1.8219e+00]],\n",
      "\n",
      "          [[ 2.0360e+00,  2.0360e+00,  2.0360e+00,  ...,  2.0360e+00,\n",
      "             2.0360e+00,  2.0360e+00],\n",
      "           [ 2.0360e+00,  2.0360e+00,  2.0360e+00,  ...,  2.0360e+00,\n",
      "             2.0360e+00,  2.0360e+00],\n",
      "           [ 2.0360e+00,  2.0360e+00,  2.0360e+00,  ...,  2.0360e+00,\n",
      "             2.0360e+00,  2.0360e+00],\n",
      "           ...,\n",
      "           [ 1.5993e+00,  1.8101e+00,  2.0360e+00,  ...,  2.0360e+00,\n",
      "             2.0360e+00,  2.0360e+00],\n",
      "           [ 1.7649e+00,  1.9005e+00,  2.0360e+00,  ...,  2.0360e+00,\n",
      "             2.0360e+00,  2.0360e+00],\n",
      "           [ 2.0360e+00,  2.0360e+00,  2.0360e+00,  ...,  2.0360e+00,\n",
      "             2.0360e+00,  2.0360e+00]]]]])), ('template_anno', tensor([[[0.2396, 0.2526, 0.5129, 0.4871],\n",
      "         [0.2006, 0.2859, 0.5909, 0.4205],\n",
      "         [0.3424, 0.0926, 0.3074, 0.8070],\n",
      "         [0.3060, 0.1702, 0.3802, 0.6518],\n",
      "         [0.2441, 0.2559, 0.5196, 0.4804],\n",
      "         [0.1934, 0.2909, 0.6053, 0.4104],\n",
      "         [0.3183, 0.1629, 0.3713, 0.6665],\n",
      "         [0.0334, 0.3651, 0.9254, 0.2619],\n",
      "         [0.2653, 0.2269, 0.4615, 0.5385],\n",
      "         [0.1813, 0.2977, 0.6296, 0.3968],\n",
      "         [0.2731, 0.2269, 0.4615, 0.5385],\n",
      "         [0.2392, 0.2530, 0.5137, 0.4863],\n",
      "         [0.2487, 0.2443, 0.4948, 0.5035],\n",
      "         [0.2567, 0.2433, 0.4945, 0.5055],\n",
      "         [0.0593, 0.3563, 0.8892, 0.2797],\n",
      "         [0.3609, 0.0688, 0.2861, 0.8546]]])), ('search_images', tensor([[[[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           ...,\n",
      "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
      "\n",
      "          [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           ...,\n",
      "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "          [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           ...,\n",
      "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]],\n",
      "\n",
      "          [[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           ...,\n",
      "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
      "\n",
      "          [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           ...,\n",
      "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "          [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           ...,\n",
      "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]]],\n",
      "\n",
      "\n",
      "         [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           ...,\n",
      "           [ 0.7515,  0.7691,  0.7867,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           [ 0.7339,  0.7691,  0.8219,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           [ 0.7515,  0.7691,  0.7691,  ..., -2.1179, -2.1179, -2.1179]],\n",
      "\n",
      "          [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           ...,\n",
      "           [ 0.6098,  0.6278,  0.6458,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           [ 0.6098,  0.6458,  0.6997,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           [ 0.6817,  0.6997,  0.6997,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "          [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           ...,\n",
      "           [ 0.4172,  0.4172,  0.4172,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           [ 0.4530,  0.4530,  0.4889,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           [ 0.5068,  0.5068,  0.4889,  ..., -1.8044, -1.8044, -1.8044]],\n",
      "\n",
      "          [[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           ...,\n",
      "           [-1.3434,  0.1353,  0.8219,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
      "\n",
      "          [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           ...,\n",
      "           [ 1.9595,  2.3014,  2.3554,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           [ 1.3116,  1.3296,  1.3836,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           [ 1.3116,  1.3836,  1.4016,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "          [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           ...,\n",
      "           [ 1.9759,  0.4889, -0.2099,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           [ 2.6400,  2.6400,  2.6400,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           [ 2.6400,  2.6400,  2.6400,  ..., -1.8044, -1.8044, -1.8044]]],\n",
      "\n",
      "\n",
      "         [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           ...,\n",
      "           [-1.1095, -1.1095, -1.0897,  ..., -0.8920, -0.9711, -0.9908],\n",
      "           [-1.2083, -1.2083, -1.2083,  ..., -0.8722, -0.9315, -0.9711],\n",
      "           [-1.2479, -1.2479, -1.2479,  ..., -0.8722, -0.9315, -0.9513]],\n",
      "\n",
      "          [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           ...,\n",
      "           [-1.3889, -1.3686, -1.3080,  ..., -0.9846, -1.0452, -1.0856],\n",
      "           [-1.5304, -1.5101, -1.4293,  ..., -0.9643, -1.0250, -1.0452],\n",
      "           [-1.5708, -1.5506, -1.4899,  ..., -0.9643, -1.0048, -1.0250]],\n",
      "\n",
      "          [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           ...,\n",
      "           [-1.2208, -1.2208, -1.2007,  ..., -0.8988, -0.9391, -0.9592],\n",
      "           [-1.2812, -1.2812, -1.2812,  ..., -0.8787, -0.9391, -0.9391],\n",
      "           [-1.3013, -1.3013, -1.3013,  ..., -0.8787, -0.9190, -0.9391]],\n",
      "\n",
      "          [[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           ...,\n",
      "           [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "           [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489],\n",
      "           [ 2.2489,  2.2489,  2.2489,  ...,  2.2489,  2.2489,  2.2489]],\n",
      "\n",
      "          [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           ...,\n",
      "           [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "           [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286],\n",
      "           [ 2.4286,  2.4286,  2.4286,  ...,  2.4286,  2.4286,  2.4286]],\n",
      "\n",
      "          [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           ...,\n",
      "           [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "           [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400],\n",
      "           [ 2.6400,  2.6400,  2.6400,  ...,  2.6400,  2.6400,  2.6400]]],\n",
      "\n",
      "\n",
      "         ...,\n",
      "\n",
      "\n",
      "         [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           ...,\n",
      "           [-2.1179, -2.1179, -2.1179,  ...,  1.6199,  1.5507,  1.5507],\n",
      "           [-2.1179, -2.1179, -2.1179,  ...,  1.5680,  1.5507,  1.5507],\n",
      "           [-2.1179, -2.1179, -2.1179,  ...,  1.5161,  1.5161,  1.5334]],\n",
      "\n",
      "          [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           ...,\n",
      "           [-2.0357, -2.0357, -2.0357,  ...,  1.9093,  1.8916,  1.8740],\n",
      "           [-2.0357, -2.0357, -2.0357,  ...,  1.8563,  1.8386,  1.8386],\n",
      "           [-2.0357, -2.0357, -2.0357,  ...,  1.8386,  1.8209,  1.8209]],\n",
      "\n",
      "          [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           ...,\n",
      "           [-1.8044, -1.8044, -1.8044,  ...,  1.9822,  1.9470,  1.9293],\n",
      "           [-1.8044, -1.8044, -1.8044,  ...,  1.9293,  1.9117,  1.9117],\n",
      "           [-1.8044, -1.8044, -1.8044,  ...,  1.8941,  1.8765,  1.8765]],\n",
      "\n",
      "          [[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           ...,\n",
      "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
      "\n",
      "          [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           ...,\n",
      "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "          [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           ...,\n",
      "           [-1.8044, -1.8044, -1.8044,  ...,  0.9431,  0.9431,  0.8902],\n",
      "           [-1.8044, -1.8044, -1.8044,  ...,  0.9431,  0.9078,  0.8726],\n",
      "           [-1.8044, -1.8044, -1.8044,  ...,  0.8726,  0.8726,  0.8902]]],\n",
      "\n",
      "\n",
      "         [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           ...,\n",
      "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179]],\n",
      "\n",
      "          [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           ...,\n",
      "           [-2.0205, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "          [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           ...,\n",
      "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044]],\n",
      "\n",
      "          [[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           ...,\n",
      "           [ 1.6696,  1.6696,  1.6696,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           [ 1.6696,  1.6696,  1.6696,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           [ 1.6696,  1.6696,  1.6696,  ..., -2.1179, -2.1179, -2.1179]],\n",
      "\n",
      "          [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           ...,\n",
      "           [ 1.8363,  1.8363,  1.8363,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           [ 1.8363,  1.8363,  1.8363,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           [ 1.8363,  1.8363,  1.8363,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "          [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           ...,\n",
      "           [ 2.0504,  2.0504,  2.0504,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           [ 2.0504,  2.0504,  2.0504,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           [ 2.0504,  2.0504,  2.0504,  ..., -1.8044, -1.8044, -1.8044]]],\n",
      "\n",
      "\n",
      "         [[[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           ...,\n",
      "           [-0.6433, -1.2043, -1.4768,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           [-0.4510, -1.2844, -1.4127,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           [-0.7074, -0.7074, -1.4447,  ..., -2.1179, -2.1179, -2.1179]],\n",
      "\n",
      "          [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           ...,\n",
      "           [-1.0198, -1.2984, -1.5278,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           [-0.5118, -1.1509, -1.4458,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           [-0.7412, -1.1017, -1.4622,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "          [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           ...,\n",
      "           [-1.0377, -1.2335, -1.3803,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           [-1.0704, -1.2498, -1.3477,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           [-1.1356, -1.2824, -1.3966,  ..., -1.8044, -1.8044, -1.8044]],\n",
      "\n",
      "          [[-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           [-2.1179, -2.1179, -2.1179,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           ...,\n",
      "           [ 1.9692,  1.9692,  1.9692,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           [ 1.9692,  1.9692,  1.9692,  ..., -2.1179, -2.1179, -2.1179],\n",
      "           [ 1.9692,  1.9692,  1.9692,  ..., -2.1179, -2.1179, -2.1179]],\n",
      "\n",
      "          [[-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           [-2.0357, -2.0357, -2.0357,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           ...,\n",
      "           [ 2.1427,  2.1427,  2.1427,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           [ 2.1427,  2.1427,  2.1427,  ..., -2.0357, -2.0357, -2.0357],\n",
      "           [ 2.1427,  2.1427,  2.1427,  ..., -2.0357, -2.0357, -2.0357]],\n",
      "\n",
      "          [[-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           [-1.8044, -1.8044, -1.8044,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           ...,\n",
      "           [ 2.3554,  2.3554,  2.3554,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           [ 2.3554,  2.3554,  2.3554,  ..., -1.8044, -1.8044, -1.8044],\n",
      "           [ 2.3554,  2.3554,  2.3554,  ..., -1.8044, -1.8044, -1.8044]]]]])), ('search_anno', tensor([[[ 0.5298, -0.8438,  0.2889,  0.2889],\n",
      "         [-0.3766,  1.8864,  0.1705,  0.2512],\n",
      "         [ 1.0542,  1.4379,  0.1204,  0.2733],\n",
      "         [ 0.0432,  1.8721,  0.0979,  0.2358],\n",
      "         [-0.2341,  1.7516,  0.1662,  0.1633],\n",
      "         [ 0.1604,  0.8655,  0.1961,  0.1476],\n",
      "         [ 0.3351,  2.3156,  0.0628,  0.1695],\n",
      "         [ 0.4468,  0.8712,  0.5810,  0.1315],\n",
      "         [-0.0659,  0.8963,  0.2236,  0.2733],\n",
      "         [-0.7457,  0.6340,  0.2672,  0.1791],\n",
      "         [ 0.1951,  0.9520,  0.1314,  0.1600],\n",
      "         [ 0.5891,  0.5681,  0.2743,  0.3000],\n",
      "         [-1.3444,  0.4793,  0.2146,  0.2299],\n",
      "         [ 1.3937,  1.9144,  0.1259,  0.1399],\n",
      "         [ 0.3832,  1.2441,  0.0496,  0.2353],\n",
      "         [-1.3481,  1.9974,  0.1829,  0.3383]]])), ('dataset', ['DepthTrack', 'DepthTrack', 'visevent', 'visevent', 'DepthTrack', 'visevent', 'visevent', 'visevent', 'DepthTrack', 'DepthTrack', 'DepthTrack', 'DepthTrack', 'visevent', 'DepthTrack', 'visevent', 'visevent']), ('test_class', ['train', 'train', None, None, 'train', None, None, None, 'train', 'train', 'train', 'train', None, 'train', None, None]), ('valid', tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]))])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [1572864], which does not match the required output shape [1, 16, 6, 128, 128]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [64], which does not match the required output shape [1, 16, 4]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [9830400], which does not match the required output shape [1, 16, 6, 320, 320]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [1572864], which does not match the required output shape [1, 16, 6, 128, 128]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [64], which does not match the required output shape [1, 16, 4]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [9830400], which does not match the required output shape [1, 16, 6, 320, 320]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [1572864], which does not match the required output shape [1, 16, 6, 128, 128]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [64], which does not match the required output shape [1, 16, 4]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [9830400], which does not match the required output shape [1, 16, 6, 320, 320]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [1572864], which does not match the required output shape [1, 16, 6, 128, 128]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [64], which does not match the required output shape [1, 16, 4]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [9830400], which does not match the required output shape [1, 16, 6, 320, 320]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [1572864], which does not match the required output shape [1, 16, 6, 128, 128]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [64], which does not match the required output shape [1, 16, 4]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [9830400], which does not match the required output shape [1, 16, 6, 320, 320]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [1572864], which does not match the required output shape [1, 16, 6, 128, 128]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [64], which does not match the required output shape [1, 16, 4]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [9830400], which does not match the required output shape [1, 16, 6, 320, 320]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [1572864], which does not match the required output shape [1, 16, 6, 128, 128]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [64], which does not match the required output shape [1, 16, 4]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [9830400], which does not match the required output shape [1, 16, 6, 320, 320]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [1572864], which does not match the required output shape [1, 16, 6, 128, 128]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [64], which does not match the required output shape [1, 16, 4]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n",
      "/media/star/data/Leezed/workspace/LeeNet/lib/data/loader.py:92: UserWarning: An output with one or more elements was resized since it had shape [9830400], which does not match the required output shape [1, 16, 6, 320, 320]. This behavior is deprecated, and in a future PyTorch release outputs will not be resized unless they have zero elements. You can explicitly reuse an out tensor t by resizing it, inplace, to zero elements with t.resize_(0). (Triggered internally at ../aten/src/ATen/native/Resize.cpp:28.)\n",
      "  return torch.stack(batch, 1, out=out)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    for i,data in enumerate(loader_train,1):\n",
    "        print(i)\n",
    "        print(data)\n",
    "        break   \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-13T11:13:20.305648300Z",
     "start_time": "2024-04-13T11:13:16.426623200Z"
    }
   },
   "id": "c8b450feb5126d1c",
   "execution_count": 8
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
