{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-16T13:56:26.261032800Z",
     "start_time": "2024-04-16T13:56:26.214616100Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from lib.actor.LeeNet import LeeNetActor\n",
    "from lib.models.backbone.pure_RMT import PureRMT\n",
    "from lib.models.LeeNet.score_pureRMT_mlp import ScorePureRMTMLP\n",
    "from lib.models.head.mlp import MLP\n",
    "from lib.trainer.LeeNet_trainer import LeeNetTrainer\n",
    "from lib.utils.base_funtion import build_dataloaders, get_optimizer_scheduler\n",
    "from lib.config.cfg_loader import env_setting\n",
    "from torch.nn.functional import l1_loss\n",
    "from torch.nn import BCEWithLogitsLoss\n",
    "from lib.utils.box_ops import giou_loss\n",
    "from lib.utils.focal_loss import FocalLoss\n",
    "import torch\n",
    "\n",
    "\n",
    "def build_model(cfg):\n",
    "    backbone = PureRMT(cfg=cfg)\n",
    "    head = MLP(input_dim=cfg.model.pureRMT.embed_dim[-1], hidden_dim=cfg.model.pureRMT.embed_dim[-1], output_dim=4, num_layers=2)\n",
    "    model = ScorePureRMTMLP(backbone, head, cfg)\n",
    "    return model\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T14:17:22.395902700Z",
     "start_time": "2024-04-16T14:17:22.283663200Z"
    }
   },
   "id": "30fca21eced96d0a",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "cfg = env_setting(cfg_name=None)\n",
    "\n",
    "loader_train, loader_val = build_dataloaders(cfg)\n",
    "\n",
    "net = build_model(cfg)\n",
    "\n",
    "focal_loss = FocalLoss()\n",
    "objective = {'giou': giou_loss, 'l1': l1_loss, 'focal': focal_loss, 'cls': BCEWithLogitsLoss()}\n",
    "loss_weight = {'giou': cfg.train.GIOU_weight, 'l1': cfg.train.L1_weight, 'focal': 1., 'cls': 1.0}\n",
    "actor = LeeNetActor(net=net, objective=objective, loss_weight=loss_weight, cfg=cfg)\n",
    "\n",
    "optimizer, lr_scheduler = get_optimizer_scheduler(net, cfg)\n",
    "\n",
    "trainer = LeeNetTrainer(actor=actor, loaders=[loader_train, loader_val], optimizer=optimizer, lr_scheduler=lr_scheduler, cfg=cfg)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T14:38:06.749879500Z",
     "start_time": "2024-04-16T14:38:06.144723Z"
    }
   },
   "id": "99089b02971c220a",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape torch.Size([16, 10, 768])\n",
      "out shape in backbone  torch.Size([16, 10, 768])\n",
      "pred_boxes shape torch.Size([16, 10, 4])\n",
      "Epoch Time: 0:00:05.576912\n",
      "Avg Data Time: 5.42236\n",
      "Avg GPU Trans Time: 0.01268\n",
      "Avg Forward Time: 0.14188\n",
      "x shape torch.Size([16, 10, 768])\n",
      "out shape in backbone  torch.Size([16, 10, 768])\n",
      "pred_boxes shape torch.Size([16, 10, 4])\n",
      "Epoch Time: 0:00:05.722600\n",
      "Avg Data Time: 2.71507\n",
      "Avg GPU Trans Time: 0.01260\n",
      "Avg Forward Time: 0.13363\n",
      "x shape torch.Size([16, 10, 768])\n",
      "out shape in backbone  torch.Size([16, 10, 768])\n",
      "pred_boxes shape torch.Size([16, 10, 4])\n",
      "Epoch Time: 0:00:05.871433\n",
      "Avg Data Time: 1.81260\n",
      "Avg GPU Trans Time: 0.01302\n",
      "Avg Forward Time: 0.13153\n",
      "x shape torch.Size([16, 10, 768])\n",
      "out shape in backbone  torch.Size([16, 10, 768])\n",
      "pred_boxes shape torch.Size([16, 10, 4])\n",
      "Epoch Time: 0:00:06.023059\n",
      "Avg Data Time: 1.36177\n",
      "Avg GPU Trans Time: 0.01324\n",
      "Avg Forward Time: 0.13075\n",
      "x shape torch.Size([16, 10, 768])\n",
      "out shape in backbone  torch.Size([16, 10, 768])\n",
      "pred_boxes shape torch.Size([16, 10, 4])\n",
      "Epoch Time: 0:00:06.168610\n",
      "Avg Data Time: 1.09125\n",
      "Avg GPU Trans Time: 0.01310\n",
      "Avg Forward Time: 0.12937\n",
      "x shape torch.Size([16, 10, 768])\n",
      "out shape in backbone  torch.Size([16, 10, 768])\n",
      "pred_boxes shape torch.Size([16, 10, 4])\n",
      "Epoch Time: 0:00:06.318720\n",
      "Avg Data Time: 0.91068\n",
      "Avg GPU Trans Time: 0.01323\n",
      "Avg Forward Time: 0.12921\n",
      "x shape torch.Size([16, 10, 768])\n",
      "out shape in backbone  torch.Size([16, 10, 768])\n",
      "pred_boxes shape torch.Size([16, 10, 4])\n",
      "Epoch Time: 0:00:06.463313\n",
      "Avg Data Time: 0.78185\n",
      "Avg GPU Trans Time: 0.01312\n",
      "Avg Forward Time: 0.12836\n",
      "x shape torch.Size([16, 10, 768])\n",
      "out shape in backbone  torch.Size([16, 10, 768])\n",
      "pred_boxes shape torch.Size([16, 10, 4])\n",
      "Epoch Time: 0:00:06.605567\n",
      "Avg Data Time: 0.68512\n",
      "Avg GPU Trans Time: 0.01323\n",
      "Avg Forward Time: 0.12735\n",
      "x shape torch.Size([16, 10, 768])\n",
      "out shape in backbone  torch.Size([16, 10, 768])\n",
      "pred_boxes shape torch.Size([16, 10, 4])\n",
      "Epoch Time: 0:00:10.323419\n",
      "Avg Data Time: 1.00453\n",
      "Avg GPU Trans Time: 0.01315\n",
      "Avg Forward Time: 0.12937\n",
      "x shape torch.Size([16, 10, 768])\n",
      "out shape in backbone  torch.Size([16, 10, 768])\n",
      "pred_boxes shape torch.Size([16, 10, 4])\n",
      "[train: 1, 10 / 3750] FPS: 15.3 (98.8)  ,  DataTime: 0.905 (0.013)  ,  ForwardTime: 0.131  ,  TotalTime: 1.049  ,  Loss/total: 0.97100  ,  Loss/giou: 0.00000  ,  Loss/l1: 0.48550  ,  Loss/location: 0.00000  ,  IoU: 0.00000\n",
      "Epoch Time: 0:00:10.485384\n",
      "Avg Data Time: 0.90484\n",
      "Avg GPU Trans Time: 0.01308\n",
      "Avg Forward Time: 0.13062\n",
      "x shape torch.Size([16, 10, 768])\n",
      "out shape in backbone  torch.Size([16, 10, 768])\n",
      "pred_boxes shape torch.Size([16, 10, 4])\n",
      "Epoch Time: 0:00:10.653702\n",
      "Avg Data Time: 0.82334\n",
      "Avg GPU Trans Time: 0.01316\n",
      "Avg Forward Time: 0.13202\n",
      "x shape torch.Size([16, 10, 768])\n",
      "out shape in backbone  torch.Size([16, 10, 768])\n",
      "pred_boxes shape torch.Size([16, 10, 4])\n",
      "Epoch Time: 0:00:10.819404\n",
      "Avg Data Time: 0.75548\n",
      "Avg GPU Trans Time: 0.01323\n",
      "Avg Forward Time: 0.13291\n",
      "x shape torch.Size([16, 10, 768])\n",
      "out shape in backbone  torch.Size([16, 10, 768])\n",
      "pred_boxes shape torch.Size([16, 10, 4])\n",
      "Epoch Time: 0:00:10.987422\n",
      "Avg Data Time: 0.69806\n",
      "Avg GPU Trans Time: 0.01319\n",
      "Avg Forward Time: 0.13394\n",
      "x shape torch.Size([16, 10, 768])\n",
      "out shape in backbone  torch.Size([16, 10, 768])\n",
      "pred_boxes shape torch.Size([16, 10, 4])\n",
      "Epoch Time: 0:00:11.150799\n",
      "Avg Data Time: 0.64878\n",
      "Avg GPU Trans Time: 0.01324\n",
      "Avg Forward Time: 0.13447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@8742.168] global loadsave.cpp:248 findDecoder imread_('/home/lzd/dataset/LasHeR/TrainingSet/trainingset/bluegirlriding/visible/v000045.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape torch.Size([16, 10, 768])\n",
      "out shape in backbone  torch.Size([16, 10, 768])\n",
      "pred_boxes shape torch.Size([16, 10, 4])\n",
      "Epoch Time: 0:00:11.314170\n",
      "Avg Data Time: 0.60613\n",
      "Avg GPU Trans Time: 0.01319\n",
      "Avg Forward Time: 0.13496\n",
      "x shape torch.Size([16, 10, 768])\n",
      "out shape in backbone  torch.Size([16, 10, 768])\n",
      "pred_boxes shape torch.Size([16, 10, 4])\n",
      "Epoch Time: 0:00:11.482571\n",
      "Avg Data Time: 0.56873\n",
      "Avg GPU Trans Time: 0.01326\n",
      "Avg Forward Time: 0.13568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@8744.190] global loadsave.cpp:248 findDecoder imread_('/home/lzd/dataset/LasHeR/TrainingSet/trainingset/fogboyscoming1_quezhen_inf_heiying/visible/v000399.jpg'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@8744.805] global loadsave.cpp:248 findDecoder imread_('/home/lzd/dataset/LasHeR/TrainingSet/trainingset/bowblkboy1-quezhen/infrared/i000257.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape torch.Size([16, 10, 768])\n",
      "out shape in backbone  torch.Size([16, 10, 768])\n",
      "pred_boxes shape torch.Size([16, 10, 4])\n",
      "Epoch Time: 0:00:13.928473\n",
      "Avg Data Time: 0.66968\n",
      "Avg GPU Trans Time: 0.01322\n",
      "Avg Forward Time: 0.13642\n",
      "x shape torch.Size([16, 10, 768])\n",
      "out shape in backbone  torch.Size([16, 10, 768])\n",
      "pred_boxes shape torch.Size([16, 10, 4])\n",
      "Epoch Time: 0:00:14.092041\n",
      "Avg Data Time: 0.63291\n",
      "Avg GPU Trans Time: 0.01317\n",
      "Avg Forward Time: 0.13681\n",
      "x shape torch.Size([16, 10, 768])\n",
      "out shape in backbone  torch.Size([16, 10, 768])\n",
      "pred_boxes shape torch.Size([16, 10, 4])\n",
      "Epoch Time: 0:00:14.258765\n",
      "Avg Data Time: 0.60000\n",
      "Avg GPU Trans Time: 0.01322\n",
      "Avg Forward Time: 0.13724\n",
      "x shape torch.Size([16, 10, 768])\n",
      "out shape in backbone  torch.Size([16, 10, 768])\n",
      "pred_boxes shape torch.Size([16, 10, 4])\n",
      "[train: 1, 20 / 3750] FPS: 22.2 (95.7)  ,  DataTime: 0.570 (0.013)  ,  ForwardTime: 0.138  ,  TotalTime: 0.721  ,  Loss/total: 0.87314  ,  Loss/giou: 0.00000  ,  Loss/l1: 0.43657  ,  Loss/location: 0.00000  ,  IoU: 0.00000\n",
      "Epoch Time: 0:00:14.426016\n",
      "Avg Data Time: 0.57043\n",
      "Avg GPU Trans Time: 0.01333\n",
      "Avg Forward Time: 0.13754\n",
      "x shape torch.Size([16, 10, 768])\n",
      "out shape in backbone  torch.Size([16, 10, 768])\n",
      "pred_boxes shape torch.Size([16, 10, 4])\n",
      "Epoch Time: 0:00:14.596395\n",
      "Avg Data Time: 0.54371\n",
      "Avg GPU Trans Time: 0.01335\n",
      "Avg Forward Time: 0.13801\n",
      "x shape torch.Size([16, 10, 768])\n",
      "out shape in backbone  torch.Size([16, 10, 768])\n",
      "pred_boxes shape torch.Size([16, 10, 4])\n",
      "Epoch Time: 0:00:14.767259\n",
      "Avg Data Time: 0.51946\n",
      "Avg GPU Trans Time: 0.01348\n",
      "Avg Forward Time: 0.13830\n",
      "x shape torch.Size([16, 10, 768])\n",
      "out shape in backbone  torch.Size([16, 10, 768])\n",
      "pred_boxes shape torch.Size([16, 10, 4])\n",
      "Epoch Time: 0:00:14.937092\n",
      "Avg Data Time: 0.49728\n",
      "Avg GPU Trans Time: 0.01344\n",
      "Avg Forward Time: 0.13872\n",
      "x shape torch.Size([16, 10, 768])\n",
      "out shape in backbone  torch.Size([16, 10, 768])\n",
      "pred_boxes shape torch.Size([16, 10, 4])\n",
      "Epoch Time: 0:00:15.103929\n",
      "Avg Data Time: 0.47688\n",
      "Avg GPU Trans Time: 0.01346\n",
      "Avg Forward Time: 0.13899\n",
      "x shape torch.Size([16, 10, 768])\n",
      "out shape in backbone  torch.Size([16, 10, 768])\n",
      "pred_boxes shape torch.Size([16, 10, 4])\n",
      "Epoch Time: 0:00:17.525812\n",
      "Avg Data Time: 0.54841\n",
      "Avg GPU Trans Time: 0.01343\n",
      "Avg Forward Time: 0.13920\n",
      "x shape torch.Size([16, 10, 768])\n",
      "out shape in backbone  torch.Size([16, 10, 768])\n",
      "pred_boxes shape torch.Size([16, 10, 4])\n",
      "Epoch Time: 0:00:17.696156\n",
      "Avg Data Time: 0.52760\n",
      "Avg GPU Trans Time: 0.01340\n",
      "Avg Forward Time: 0.13962\n",
      "x shape torch.Size([16, 10, 768])\n",
      "out shape in backbone  torch.Size([16, 10, 768])\n",
      "pred_boxes shape torch.Size([16, 10, 4])\n",
      "Epoch Time: 0:00:17.864705\n",
      "Avg Data Time: 0.50837\n",
      "Avg GPU Trans Time: 0.01342\n",
      "Avg Forward Time: 0.13987\n",
      "x shape torch.Size([16, 10, 768])\n",
      "out shape in backbone  torch.Size([16, 10, 768])\n",
      "pred_boxes shape torch.Size([16, 10, 4])\n",
      "Epoch Time: 0:00:18.032438\n",
      "Avg Data Time: 0.49053\n",
      "Avg GPU Trans Time: 0.01345\n",
      "Avg Forward Time: 0.14004\n",
      "x shape torch.Size([16, 10, 768])\n",
      "out shape in backbone  torch.Size([16, 10, 768])\n",
      "pred_boxes shape torch.Size([16, 10, 4])\n",
      "Epoch Time: 0:00:18.201677\n",
      "Avg Data Time: 0.47391\n",
      "Avg GPU Trans Time: 0.01347\n",
      "Avg Forward Time: 0.14026\n",
      "x shape torch.Size([16, 10, 768])\n",
      "out shape in backbone  torch.Size([16, 10, 768])\n",
      "pred_boxes shape torch.Size([16, 10, 4])\n",
      "[train: 1, 30 / 3750] FPS: 26.1 (92.8)  ,  DataTime: 0.458 (0.013)  ,  ForwardTime: 0.141  ,  TotalTime: 0.612  ,  Loss/total: 0.80582  ,  Loss/giou: 0.00000  ,  Loss/l1: 0.40291  ,  Loss/location: 0.00000  ,  IoU: 0.00000\n",
      "Epoch Time: 0:00:18.374030\n",
      "Avg Data Time: 0.45848\n",
      "Avg GPU Trans Time: 0.01349\n",
      "Avg Forward Time: 0.14050\n",
      "x shape torch.Size([16, 10, 768])\n",
      "out shape in backbone  torch.Size([16, 10, 768])\n",
      "pred_boxes shape torch.Size([16, 10, 4])\n",
      "Epoch Time: 0:00:18.553603\n",
      "Avg Data Time: 0.44398\n",
      "Avg GPU Trans Time: 0.01346\n",
      "Avg Forward Time: 0.14107\n",
      "x shape torch.Size([16, 10, 768])\n",
      "out shape in backbone  torch.Size([16, 10, 768])\n",
      "pred_boxes shape torch.Size([16, 10, 4])\n",
      "Epoch Time: 0:00:18.728076\n",
      "Avg Data Time: 0.43034\n",
      "Avg GPU Trans Time: 0.01347\n",
      "Avg Forward Time: 0.14144\n",
      "x shape torch.Size([16, 10, 768])\n",
      "out shape in backbone  torch.Size([16, 10, 768])\n",
      "pred_boxes shape torch.Size([16, 10, 4])\n",
      "Epoch Time: 0:00:21.320124\n",
      "Avg Data Time: 0.49107\n",
      "Avg GPU Trans Time: 0.01344\n",
      "Avg Forward Time: 0.14155\n",
      "x shape torch.Size([16, 10, 768])\n",
      "out shape in backbone  torch.Size([16, 10, 768])\n",
      "pred_boxes shape torch.Size([16, 10, 4])\n",
      "Epoch Time: 0:00:21.484521\n",
      "Avg Data Time: 0.47684\n",
      "Avg GPU Trans Time: 0.01341\n",
      "Avg Forward Time: 0.14164\n",
      "x shape torch.Size([16, 10, 768])\n",
      "out shape in backbone  torch.Size([16, 10, 768])\n",
      "pred_boxes shape torch.Size([16, 10, 4])\n",
      "Epoch Time: 0:00:21.652367\n",
      "Avg Data Time: 0.46345\n",
      "Avg GPU Trans Time: 0.01343\n",
      "Avg Forward Time: 0.14176\n",
      "x shape torch.Size([16, 10, 768])\n",
      "out shape in backbone  torch.Size([16, 10, 768])\n",
      "pred_boxes shape torch.Size([16, 10, 4])\n",
      "Epoch Time: 0:00:21.819010\n",
      "Avg Data Time: 0.45094\n",
      "Avg GPU Trans Time: 0.01329\n",
      "Avg Forward Time: 0.14186\n",
      "x shape torch.Size([16, 10, 768])\n",
      "out shape in backbone  torch.Size([16, 10, 768])\n",
      "pred_boxes shape torch.Size([16, 10, 4])\n",
      "Epoch Time: 0:00:21.985340\n",
      "Avg Data Time: 0.43899\n",
      "Avg GPU Trans Time: 0.01331\n",
      "Avg Forward Time: 0.14190\n",
      "x shape torch.Size([16, 10, 768])\n",
      "out shape in backbone  torch.Size([16, 10, 768])\n",
      "pred_boxes shape torch.Size([16, 10, 4])\n",
      "Epoch Time: 0:00:22.158562\n",
      "Avg Data Time: 0.42774\n",
      "Avg GPU Trans Time: 0.01332\n",
      "Avg Forward Time: 0.14206\n",
      "x shape torch.Size([16, 10, 768])\n",
      "out shape in backbone  torch.Size([16, 10, 768])\n",
      "pred_boxes shape torch.Size([16, 10, 4])\n",
      "Epoch Time: 0:00:22.332415\n",
      "Avg Data Time: 0.41700\n",
      "Avg GPU Trans Time: 0.01330\n",
      "Avg Forward Time: 0.14233\n",
      "x shape torch.Size([16, 10, 768])\n",
      "out shape in backbone  torch.Size([16, 10, 768])\n",
      "pred_boxes shape torch.Size([16, 10, 4])\n",
      "[train: 1, 40 / 3750] FPS: 28.4 (89.3)  ,  DataTime: 0.407 (0.013)  ,  ForwardTime: 0.143  ,  TotalTime: 0.563  ,  Loss/total: 0.75978  ,  Loss/giou: 0.00000  ,  Loss/l1: 0.37989  ,  Loss/location: 0.00000  ,  IoU: 0.00000\n",
      "Epoch Time: 0:00:22.511597\n",
      "Avg Data Time: 0.40677\n",
      "Avg GPU Trans Time: 0.01333\n",
      "Avg Forward Time: 0.14270\n",
      "x shape torch.Size([16, 10, 768])\n",
      "out shape in backbone  torch.Size([16, 10, 768])\n",
      "pred_boxes shape torch.Size([16, 10, 4])\n",
      "Epoch Time: 0:00:25.017874\n",
      "Avg Data Time: 0.45403\n",
      "Avg GPU Trans Time: 0.01330\n",
      "Avg Forward Time: 0.14286\n",
      "x shape torch.Size([16, 10, 768])\n",
      "out shape in backbone  torch.Size([16, 10, 768])\n",
      "pred_boxes shape torch.Size([16, 10, 4])\n",
      "Epoch Time: 0:00:25.196888\n",
      "Avg Data Time: 0.44341\n",
      "Avg GPU Trans Time: 0.01333\n",
      "Avg Forward Time: 0.14319\n",
      "Training crashed at epoch 1\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Caught FileNotFoundError in DataLoader worker process 2.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/anaconda/envs/lzd-LeeNet/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 202, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/anaconda/envs/lzd-LeeNet/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/anaconda/envs/lzd-LeeNet/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/lzd/workspace/LeeNet/lib/data/sampler.py\", line 98, in __getitem__\n    return self.getitem()\n  File \"/home/lzd/workspace/LeeNet/lib/data/sampler.py\", line 212, in getitem\n    seq_id, visible, seq_info_dict = self.sample_seq_from_dataset(dataset, is_video_dataset)\n  File \"/home/lzd/workspace/LeeNet/lib/data/sampler.py\", line 327, in sample_seq_from_dataset\n    seq_info_dict = dataset.get_sequence_info(seq_id)\n  File \"/home/lzd/workspace/LeeNet/lib/dataset/LasHeR.py\", line 62, in get_sequence_info\n    bbox = self._read_bb_anno(seq_path)\n  File \"/home/lzd/workspace/LeeNet/lib/dataset/LasHeR.py\", line 54, in _read_bb_anno\n    rgb_gt = pandas.read_csv(rgb_bb_anno_file, delimiter=',', header=None, dtype=np.float32, na_filter=False, low_memory=False).values\n  File \"/usr/local/anaconda/envs/lzd-LeeNet/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 912, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/usr/local/anaconda/envs/lzd-LeeNet/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 577, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/usr/local/anaconda/envs/lzd-LeeNet/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 1407, in __init__\n    self._engine = self._make_engine(f, self.engine)\n  File \"/usr/local/anaconda/envs/lzd-LeeNet/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 1661, in _make_engine\n    self.handles = get_handle(\n  File \"/usr/local/anaconda/envs/lzd-LeeNet/lib/python3.8/site-packages/pandas/io/common.py\", line 859, in get_handle\n    handle = open(\nFileNotFoundError: [Errno 2] No such file or directory: '/home/lzd/dataset/LasHeR/TrainingSet/trainingset/cameraman_1202/visible.txt'\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[29], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcfg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mepoch\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/workspace/LeeNet/lib/trainer/base_trainer.py:58\u001B[0m, in \u001B[0;36mBaseTrainer.train\u001B[0;34m(self, max_epochs, load_latest, fail_safe, load_previous_ckpt, distill)\u001B[0m\n\u001B[1;32m     55\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mepoch \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m, max_epochs \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m     56\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mepoch \u001B[38;5;241m=\u001B[39m epoch\n\u001B[0;32m---> 58\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlr_scheduler\u001B[38;5;241m.\u001B[39mstep()\n\u001B[1;32m     62\u001B[0m     \u001B[38;5;66;03m# if self.lr_scheduler is not None:\u001B[39;00m\n\u001B[1;32m     63\u001B[0m     \u001B[38;5;66;03m#     if self.settings.scheduler_type != 'cosine':\u001B[39;00m\n\u001B[1;32m     64\u001B[0m     \u001B[38;5;66;03m#         self.lr_scheduler.step()\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     72\u001B[0m     \u001B[38;5;66;03m#         if self.settings.local_rank in [-1, 0]:\u001B[39;00m\n\u001B[1;32m     73\u001B[0m     \u001B[38;5;66;03m#             self.save_checkpoint()\u001B[39;00m\n",
      "File \u001B[0;32m~/workspace/LeeNet/lib/trainer/LeeNet_trainer.py:27\u001B[0m, in \u001B[0;36mLeeNetTrainer.train_epoch\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m loader \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloaders:\n\u001B[1;32m     26\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mepoch \u001B[38;5;241m%\u001B[39m loader\u001B[38;5;241m.\u001B[39mepoch_interval \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m---> 27\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcycle_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mloader\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stats_new_epoch()\n",
      "File \u001B[0;32m~/workspace/LeeNet/lib/trainer/LeeNet_trainer.py:59\u001B[0m, in \u001B[0;36mLeeNetTrainer.cycle_dataset\u001B[0;34m(self, loader)\u001B[0m\n\u001B[1;32m     55\u001B[0m torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(loader\u001B[38;5;241m.\u001B[39mtraining)\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_timing()\n\u001B[0;32m---> 59\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, data \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(loader, \u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m     60\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdata_read_done_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m     61\u001B[0m     data \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n",
      "File \u001B[0;32m/usr/local/anaconda/envs/lzd-LeeNet/lib/python3.8/site-packages/torch/utils/data/dataloader.py:517\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    515\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    516\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()\n\u001B[0;32m--> 517\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    518\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    519\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    520\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    521\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m/usr/local/anaconda/envs/lzd-LeeNet/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1179\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1177\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_task_info[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_rcvd_idx]) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m2\u001B[39m:\n\u001B[1;32m   1178\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_task_info\u001B[38;5;241m.\u001B[39mpop(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_rcvd_idx)[\u001B[38;5;241m1\u001B[39m]\n\u001B[0;32m-> 1179\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_process_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1181\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_shutdown \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tasks_outstanding \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[1;32m   1182\u001B[0m idx, data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_data()\n",
      "File \u001B[0;32m/usr/local/anaconda/envs/lzd-LeeNet/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1225\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._process_data\u001B[0;34m(self, data)\u001B[0m\n\u001B[1;32m   1223\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_try_put_index()\n\u001B[1;32m   1224\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(data, ExceptionWrapper):\n\u001B[0;32m-> 1225\u001B[0m     \u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreraise\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1226\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m data\n",
      "File \u001B[0;32m/usr/local/anaconda/envs/lzd-LeeNet/lib/python3.8/site-packages/torch/_utils.py:429\u001B[0m, in \u001B[0;36mExceptionWrapper.reraise\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    425\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexc_type, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmessage\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[1;32m    426\u001B[0m     \u001B[38;5;66;03m# Some exceptions have first argument as non-str but explicitly\u001B[39;00m\n\u001B[1;32m    427\u001B[0m     \u001B[38;5;66;03m# have message field\u001B[39;00m\n\u001B[1;32m    428\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexc_type(message\u001B[38;5;241m=\u001B[39mmsg)\n\u001B[0;32m--> 429\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexc_type(msg)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: Caught FileNotFoundError in DataLoader worker process 2.\nOriginal Traceback (most recent call last):\n  File \"/usr/local/anaconda/envs/lzd-LeeNet/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 202, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/usr/local/anaconda/envs/lzd-LeeNet/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/usr/local/anaconda/envs/lzd-LeeNet/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/home/lzd/workspace/LeeNet/lib/data/sampler.py\", line 98, in __getitem__\n    return self.getitem()\n  File \"/home/lzd/workspace/LeeNet/lib/data/sampler.py\", line 212, in getitem\n    seq_id, visible, seq_info_dict = self.sample_seq_from_dataset(dataset, is_video_dataset)\n  File \"/home/lzd/workspace/LeeNet/lib/data/sampler.py\", line 327, in sample_seq_from_dataset\n    seq_info_dict = dataset.get_sequence_info(seq_id)\n  File \"/home/lzd/workspace/LeeNet/lib/dataset/LasHeR.py\", line 62, in get_sequence_info\n    bbox = self._read_bb_anno(seq_path)\n  File \"/home/lzd/workspace/LeeNet/lib/dataset/LasHeR.py\", line 54, in _read_bb_anno\n    rgb_gt = pandas.read_csv(rgb_bb_anno_file, delimiter=',', header=None, dtype=np.float32, na_filter=False, low_memory=False).values\n  File \"/usr/local/anaconda/envs/lzd-LeeNet/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 912, in read_csv\n    return _read(filepath_or_buffer, kwds)\n  File \"/usr/local/anaconda/envs/lzd-LeeNet/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 577, in _read\n    parser = TextFileReader(filepath_or_buffer, **kwds)\n  File \"/usr/local/anaconda/envs/lzd-LeeNet/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 1407, in __init__\n    self._engine = self._make_engine(f, self.engine)\n  File \"/usr/local/anaconda/envs/lzd-LeeNet/lib/python3.8/site-packages/pandas/io/parsers/readers.py\", line 1661, in _make_engine\n    self.handles = get_handle(\n  File \"/usr/local/anaconda/envs/lzd-LeeNet/lib/python3.8/site-packages/pandas/io/common.py\", line 859, in get_handle\n    handle = open(\nFileNotFoundError: [Errno 2] No such file or directory: '/home/lzd/dataset/LasHeR/TrainingSet/trainingset/cameraman_1202/visible.txt'\n"
     ]
    }
   ],
   "source": [
    "trainer.train(cfg.train.epoch)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T14:38:33.244557Z",
     "start_time": "2024-04-16T14:38:07.902728600Z"
    }
   },
   "id": "1057de9bd0aeecbb",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@5554.715] global loadsave.cpp:248 findDecoder imread_('/home/lzd/dataset/LasHeR/TrainingSet/trainingset/motowithgood/visible/v000000.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "odict_keys(['template_images', 'template_anno', 'search_images', 'search_anno', 'dataset', 'test_class', 'valid'])\n",
      "template_images torch.Size([1, 16, 6, 128, 128])\n",
      "search_images torch.Size([1, 16, 6, 320, 320])\n",
      "search_anno torch.Size([1, 16, 4])\n",
      "x shape torch.Size([16, 10, 768])\n"
     ]
    }
   ],
   "source": [
    "# from lib.models.layer.patch_embed import PatchEmbed\n",
    "# from lib.models.backbone.pure_RMT import PureRMT\n",
    "# import torch\n",
    "# \n",
    "# rgb = None\n",
    "# modal = None\n",
    "# \n",
    "# device = torch.device(\"cuda:1\")\n",
    "# embed_dim = 768\n",
    "# patch_embed = PatchEmbed(patch_size=16, in_chans=3, embed_dim=embed_dim, flatten=False).to(device)\n",
    "# # relpos = RelPos2d(embed_dim=embed_dim, num_heads=12, initial_value=1, heads_range=3).to(device)\n",
    "# # ret_block = RetBlock(retention='whole', embed_dim=embed_dim, num_heads=12, ffn_dim=96).to(device)\n",
    "# # score = ScoreLayerUseConv(embed_dim=embed_dim).to(device)\n",
    "# template_score = None\n",
    "# backbone = PureRMT(cfg=cfg).to(device)\n",
    "# \n",
    "# for i, data in enumerate(loader_train, 1):\n",
    "#     print(i)\n",
    "#     print(data.keys())\n",
    "#     # print(data['test_class'])\n",
    "#     # print(data['dataset'])\n",
    "#     print(\"template_images\", data['template_images'].shape)\n",
    "#     print(\"search_images\", data['search_images'].shape)\n",
    "#     print(\"search_anno\", data['search_anno'].shape)\n",
    "# \n",
    "#     template = data['template_images'][0].to(device)\n",
    "#     search = data['search_images'][0].to(device)\n",
    "#     # template, template_patch_num = patch_embed(template)\n",
    "#     # print(\"template\", template.shape)\n",
    "#     # positive, uncertain, negative = score(template)\n",
    "#     # template = template.permute(0,2,3,1) # B,C,H,W -> B,H,W,C\n",
    "#     backbone(template, search)\n",
    "# \n",
    "#     break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T13:45:17.248957500Z",
     "start_time": "2024-04-16T13:45:08.607838Z"
    }
   },
   "id": "c8b450feb5126d1c",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# print(template_score.shape)\n",
    "# print(template_score)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T13:45:17.267902200Z",
     "start_time": "2024-04-16T13:45:17.251946700Z"
    }
   },
   "id": "187929b3f836925e",
   "execution_count": 10
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
